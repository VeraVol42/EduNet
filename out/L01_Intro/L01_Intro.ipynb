{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BPcyQRmXq8I"
   },
   "source": [
    "# 1.1 Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRJ-JLXkb2PN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHiB-TsSVCcV"
   },
   "source": [
    "\n",
    "### 1.1.1 Место глубокого обучения и нейронных сетей в ИИ\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro1.png\" >\n",
    "\n",
    "Существует множество разных определений, однако большая часть из них завязана на человеко-машинном взаимодействии, то есть это алгоритмы или методы, которые либо имитируют поведение людей, либо позволяют машине вести себя аналогично людям (то есть проявлять некоторое интеллектуальное-разумное поведение). Область ИИ не ограничивалась исключительно машинным обучением, которое состоит из обучения на примерах. В ИИ входит целый ряд алгоритмов, например многоагентные системы (расшифровка) или базы знаний, в которых люди создают связи между разными понятиями.\n",
    "\n",
    "**Искусственный интеллект (AI/ИИ)**  ~= область ИТ/Computer science связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение(ML)** - подраздел ИИ связанный с обучением на данных, он не единственный. Например базы знаний или многоагентные системы также относят к разделам ИИ. \n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** ~= Многослойная нейросеть (MLP = multi layer perceptron)\n",
    "\n",
    "Однако сейчас мы рассмотрим более узкую область, связанную с МЛ. Модели, которые имеют несколько слоев называются глубокими или нейросетевыми. Хотя если мы возьмем один слой такой модели (например линейный классификатор, он же перцептрон), он перестанет быть глубокой моделью, хотя по факту он и является простейшей нейросетью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6uYWy01di2p"
   },
   "source": [
    "### 1.1.2 Области применения DL\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/Intro2.jpg\" >\n",
    "\n",
    "В последнее время именно такого рода модели показываю высокую эффективность в тех областях, в которых влияние человека казалось превалирующим. В частности это человеко-компьютерное зрение (Computer Vision, CV), распознавание естественного языка (NLP, извлечение смысла, машинный перевод) и речи. В рамка курса мы рассмотрим как эта область может применяться на практических задачах и моделях, их решающих. Также мы познакомимся с результатами самых современных исследований по теме. \n",
    "\n",
    "В данном курсе мы подробно рассмотрим технологии DL применяющиеся в этих областях.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TiPYPVaeNiZ"
   },
   "source": [
    "### 1.1.3 Связь DL с наукой\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro3.png\" >\n",
    "\n",
    "Помимо прикладных задач существуют еще и научные исследования, результаты которых до известной степени непредсказуемы. Несльзя исключить что он появятся в областях где технологии DL до сих пор активно не использовались.\n",
    "\n",
    " Поддержка такого рода исследований есть основная задача курса нашего курса.\n",
    "\n",
    "\n",
    " Вариант2:\n",
    "\n",
    " Мы видим что NN уже нашли применение в множестве массовых(типовых) задач которые нас окружают.\n",
    "\n",
    "Однако каждая научная работа индивидуальна, в этом состоит сложность: только автор понимает как обрабатываются данные в его предметной области и как следует оценить результат.\n",
    "\n",
    "Но не всегда ученые особенно из естественных или гуманитарных областей готовы самостоятельно применить ML к объекту своих исследований.\n",
    "Поэтому мы здесь ...\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzTmT5m5e-hN"
   },
   "source": [
    "# 1.2 История глубокого обучения\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro4.png\" >\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro5.png\" >\n",
    "\n",
    "На изображении вы видите перцептрон - по сути первую нейросеть, которая появилась более полувека назад. Это однослойная нейронная сеть, которая сейчас не отнесли бы к моделям глубокого обучения. \n",
    "\n",
    "Перцептрон состоит из трёх типов элементов, а именно: поступающие от датчиков **сигналы** передаются **ассоциативным элементам**, а затем **реагирующим элементам**. Таким образом, перцептроны позволяют создать набор «ассоциаций» между входными стимулами и необходимой реакцией на выходе. \n",
    "В биологическом плане это соответствует преобразованию, например, зрительной информации в физиологический ответ от двигательных нейронов. \n",
    "\n",
    "Суть модели достаточно простая: на вход подаются данные и каждому присваивается вес, на выходе суммируются, далее применяется (пороговая) функция активации. Грубая аналогия - нейрон человеческого мозга, который работает по такому же принципу. \n",
    "На тот момент это стало прорывом и захватило великие умы. Был построен суперкомпьютер, который занимал несколько помещений.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro61.png\" >\n",
    "\n",
    "Однако уже через несколько лет было доказано, что перцептрон не может воспроизвести ряд простых функций, например функцию **xor**, продемонстрированую в таблице. \n",
    "\n",
    "После этого открытия интерес к нейросетям резко падал и они находились в забвении. По сути, даже опубликовать статью по данной теме было затруднительно.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro6.png\" >\n",
    "\n",
    "Одной из важнейших работ связанных с глубоким обучением является эксперимент американских биологов из Гарварда. В 1959 были изучены реакции определенных участков кошачьего мозга на определенные простые визуальные стимулы. \n",
    "Как и большая часть открытий, это выяснилось абсолютно случайно. \n",
    "\n",
    "В мозг кошке был вживлен электрод чтобы определить на какой рисунок будет реакция. Однако стоит вспомнить, что в то время слайды переключались последовательным движением и именно на это движение случилась реакция. Как только менялся слайд и по экрану проходила граница затвора, по сути простая прямая линия, реакция передавалась и записывалась.\n",
    "\n",
    "После ряда экспериментов выяснилось, что существуют клетки, реагирующие на простые формы (линии и углы), на движение и движение в определенном направлении или определенной формы. \n",
    "\n",
    "Слои этих клеток образуют определенного рода иерархию и именно эта идея лежит в основе концепции нейросетевых методов.  \n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro7.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V-s9vYSW21U"
   },
   "source": [
    "### 1.2.2 Победа нейросети AlexNet на соревновании ImageNet в 2012\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro8.png\" >\n",
    "\n",
    "### 1.2.3 ImageNet: Large Scale Visual Recognition Challenge (ILSVRC)\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro5.png\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUEkABb2lllH"
   },
   "source": [
    "## 1.3 Области применения DL в настоящее время\n",
    "\n",
    "### 1.3.1  Робототехника\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro6.png\" >\n",
    "Беспилотные автомобили Self-Driving Car и дроны\n",
    "Промышленные и бытовые роботы.\n",
    "\n",
    "### 1.3.2 Безопасность\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro7.png\" >\n",
    "\n",
    "\n",
    "Видеоаналитика, контроль доступа, распознавние лиц, номеров.\n",
    "\n",
    "\n",
    "### 1.3.3 Интернет и дополненная реальность\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro8.png\" >\n",
    "\n",
    "Поиск в том числе семантический. Анализ контента, в том числе визуального. Машинный перевод. Распознавание речи.\n",
    "\n",
    "\n",
    "\n",
    "### 1.3.4 Медицина\n",
    "\n",
    "- добавить примеров\n",
    "\n",
    "### 1.3.5 Применение DL в научных исследованиях\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro9.png\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro10.png\" >\n",
    "\n",
    "\n",
    "\n",
    "### 1.3.7 Причины успехов технологий на основе DL\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro11.png\" >\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXDX8IY8xw_3"
   },
   "source": [
    "## 1.4 Задачи решаемые при помощи машинного обучения\n",
    "\n",
    "### 1.4.1 Извлечение закономерностей\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro13.png\" >\n",
    "\n",
    "Ученый многократно наблюдает за ходом процесса и делает обобщения.\n",
    "\n",
    "Результатом такой работы является модель описывающая некоторые процессы реального мира.\n",
    "\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro14.png\" >\n",
    "\n",
    "ML - технология которая позволяет выявлять закономерности в данных и обобщать их. \n",
    "\n",
    "Результатом обучения такой модели является набор весов. \n",
    "\n",
    "По сути это набор коэффициентов для некоторого математического выражения.\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro15.png\" >\n",
    "\n",
    "Законы Ньютоны не сформулированны для яблок.\n",
    "Для описания закономерностей в науке используются абстракции:  сила, масса ускорение которыми описываются реальные объекты.\n",
    "\n",
    "Данные для ML моделей тоже должны быть подготовлены. Типичная форма такой абстракции вектор чисел.\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro16.png\" >\n",
    "\n",
    "Второй частью процесса обучения является оценка результата. \n",
    "\n",
    "Полученный результат сравнивают с эталонным  и если разница велика - корректируют модель.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEk8ruzC1BRb"
   },
   "source": [
    "## Пример\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro17.png\" >\n",
    "\n",
    "Нужно посчитать количество шагов используя показания акселерометра встроенного в шагомер. \n",
    "\n",
    "#### Вариант №1\n",
    "\n",
    "Написать программу вида:\n",
    "\n",
    "if x[i] > x[i - k] and y[i] > y[i - k] and ...\n",
    "  ....\n",
    "else:\n",
    "  ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDxLDZPo1rjl"
   },
   "source": [
    "\n",
    "Вариант №2\n",
    "\n",
    "Обучить модель\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro18.png\" >\n",
    "\n",
    "При этом можно не занать ничего о природе сигналов. Важно лиш собрать достаточное количество данных и разметить их.\n",
    "Разметка в данном случае будет заключаться в с боре информации о том сколько фактически шагов сделал человек.\n",
    "\n",
    "## 1.4.3 Базовые задачи\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro19.png\" >\n",
    "\n",
    "## 1.4.3 Виды данных\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro20.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DukPy4wh1gBW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o346mPzulsAV"
   },
   "source": [
    "\n",
    "#1.4.4 Оценка результата\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-17.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-18.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-19.jpg\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/accuracy.png\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-21.jpg\" >\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDG77F4f4zzx"
   },
   "source": [
    "## 1.5 Примеры задач решаемых при помощи методов машинного обучения\n",
    "\n",
    "\n",
    "Рассмотрим примеры решения задач классификации и линейной регресии на различных типах данных.\n",
    "\n",
    "\n",
    "Будем использовать библиотеки:\n",
    "\n",
    "* [skilearn](https://scikit-learn.org/stable/) - 'toy' датасеты, ML алгорытмы \n",
    "* [pandas](https://pandas.pydata.org/) - удобная работа с табличными данными\n",
    "\n",
    "познакомимся с инструментами:\n",
    "\n",
    "* **Pytorch** \n",
    "* **Tensorboard**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLlvxAHKxESh"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6y12nR9YpxU"
   },
   "source": [
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-16.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9wREYtJ6-6w"
   },
   "source": [
    "### 1.5.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2gzAX-ZYrUX"
   },
   "outputs": [],
   "source": [
    "# Классификация вин \n",
    "# Используем библиотеку sklearn: https://scikit-learn.org/stable/ \n",
    "\n",
    "import sklearn \n",
    "from sklearn.datasets import load_wine\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "# Загрузка датасета\n",
    "data = load_wine(return_X_y = True) # Так же можно получить данные в Bunch(словарь) или pandas DataFrame\n",
    "\n",
    "features = data[0] # Массив 178x13 178 бутылок у каждой 13 признаков\n",
    "class_labels = data[1] # Массив из 178 элементов каждый элемент это число обозначающее класс к которому относиться данная бутылка : 0,1 2  \n",
    "print(\"Данные\",features.shape)\n",
    "print(\"Номер класса\",class_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tohStSfdt-NE"
   },
   "source": [
    "### 1.5.2 Визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключим библиотеку для работы с табличнымии данными: https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "data_bunch = load_wine(return_X_y = False)\n",
    "print(data_bunch.keys())\n",
    "\"\"\"\n",
    "  Если параметр return_X_y == False\n",
    "  Данные в объекте Bunch: https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch \n",
    "  По сути это словарь.\n",
    "  Что бы отобразить данные в виде таблицы преобразуем их в формат pandas.DataFrame\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame(data_bunch.data, columns=data_bunch.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olpH1dK3Nc-p"
   },
   "source": [
    "Каждая строка в таблице может быть интерпретированна как вектор из 13 элементов. Можно интерпретировать такой вектор как координаты точки в 13 - мерном пространстве. Именно с таким представлением работают большинство алгоритмов машинного обучения. \n",
    "\n",
    "Визуализировать 13-мерное пространство не получиться :(. Но можно визуализировать проекцию данных в 3-х мерное пространство. Для этого воспользуемся инструментом projector из tensorboard\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательный метод для запуска Tensorboard в Colab\n",
    "\n",
    "# Fix: https://stackoverflow.com/questions/60730544/tensorboard-colab-tensorflow-api-v1-io-gfile-has-no-attribute-get-filesystem\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Запуск Tensorboard в Colab\n",
    "def reinit_tensorboard(clear_log = True):\n",
    "  # Лог-файлы читаются из этого каталога: \n",
    "  logs_base_dir = \"runs\"\n",
    "  if clear_log:\n",
    "    # Очистка логов\n",
    "    #!rm -rfv {logs_base_dir}/*\n",
    "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
    "    os.makedirs(logs_base_dir, exist_ok=True)\n",
    "  # Магия Colab\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtb8It_Rv3e1"
   },
   "source": [
    "После загрузки Tensorboard измените значение опции \"Color by\" на \"label 3 colors\" что бы объекты принадлежащие к разным классам отображались разными цветами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "np_f = numpy.array(features)\n",
    "writer.add_embedding(np_f, metadata=class_labels )\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjktILYlY99H"
   },
   "source": [
    "Рассказ про PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qM3rjfEObMd"
   },
   "source": [
    "Видно что объекты классов 1 и 2 линейно не разделимы в 2-х измерениях. По этой причине так популярен переход к пространствам большей размерности. \n",
    "\n",
    "Обратите внимание что данные центрированны около нуля - это результат нормализации которой они подверглись в Tensorboard.\n",
    "\n",
    "Нам тоже потребуется нормализовыть данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NWTf-ZPKXc"
   },
   "source": [
    "## 1.5.3 Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udGzAucjZIUr"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем это средствами pytorch\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "\n",
    "\n",
    "# Отобразим значения двух параметров значения которых отличаются примерно на порядок\n",
    "f_names = data_bunch.feature_names\n",
    "for i, feature in enumerate(features):\n",
    "  writer.add_scalars(\"Raw_2_par\",{ \n",
    "      f_names[1]:feature[1], # malic_acid\n",
    "      f_names[3]:feature[3],  # alcalinity_of_ash\n",
    "     } ) \n",
    "\n",
    "# Добавим еще один значения которого отличается от вторго на 2 порядка\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "  writer.add_scalars(\"Raw_3par\",{ \n",
    "                                     f_names[1]:feature[1], # malic_acid\n",
    "                                     f_names[3]:feature[3],  # alcalinity_of_ash\n",
    "                                     f_names[12]:feature[12] # proline \n",
    "                                     } ) \n",
    "\n",
    "# Добавим гистограмму для сырых данных.\n",
    "writer.add_histogram(\"1.Raw\" , features[:,3])\n",
    "writer.add_histogram(\"1.Raw\" , features[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# Преобразовали данные к torch.Tensor \n",
    "tensor_f = torch.tensor(features)\n",
    "\n",
    "# Mini-Max  нормализация\n",
    "\n",
    "# torch.min и torch.max возвращают кортежи (values, indexes)\n",
    "# https://pytorch.org/docs/stable/generated/torch.min.html#torch.min\n",
    "\n",
    "min_values, _  = tensor_f.min(dim=1,keepdim=True)  # shape = (178,1)\n",
    "max_values, _  = tensor_f.max(dim=1,keepdim=True)  # shape = (178,1)\n",
    "\n",
    "# Вычитаем минимальное значение\n",
    "min_max_centered = tensor_f - min_values\n",
    "# Делим на среднее\n",
    "min_max_normalized =  min_max_centered / (max_values - min_values)\n",
    "\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,3])\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,1])\n",
    "\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,3])\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,1])\n",
    "\n",
    "# Стандартизация / Z-нормализация\n",
    "\n",
    "# Вычитаем среднее\n",
    "centered = tensor_f - tensor_f.mean(dim=0)\n",
    "# Разделим на стандартное отклонение\n",
    "normalized = centered / tensor_f.std(dim=0)\n",
    "\n",
    "# Добавим гистограмму для стандартизированных данных в Tensorboard\n",
    "writer.add_histogram(\"3.Centered\" , centered[:,3])\n",
    "writer.add_histogram(\"3.Centered\" , centered[:,1])\n",
    "\n",
    "writer.add_histogram(\"3.Normalized\" , normalized[:,3])\n",
    "writer.add_histogram(\"3.Normalized\" , normalized[:,1])\n",
    "\n",
    "\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , features[:,1])\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , min_max_normalized[:,1])\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , normalized[:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9Y5GHEqnLp9"
   },
   "source": [
    "## 1. После загрузки Tensorboard выберите пункт меню \"SCALARS\"\n",
    "затем 'Horizontal Axis' = Relative\n",
    "\n",
    "Значения в разных масштабах - несравнимы между собой\n",
    "\n",
    "## 2. выберите пункт меню \"HISTOGRAMS\"\n",
    "затем Offset time axis = WALL или RELATIVE\n",
    "\n",
    "Наглядное приемущество Стандартизации перед max-min нормализацией\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj3nWSjhmtnJ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf-95rOeHYat"
   },
   "source": [
    "### 1.5.4 Обучение\n",
    "\n",
    "Базовая документация\n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "Пример использования SVM классификатора\n",
    "https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, class_labels, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"X_test\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "# Обучаем модель на части данных\n",
    "lin_clf.fit(X_train, y_train)\n",
    "\n",
    "# Получаем предсказания\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "print(\"y_pred\",y_pred.shape)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm7-6_CbHfEa"
   },
   "source": [
    "### 1.5.5  Посчитать Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for i in range(1e4,1e6,0.)\n",
    "\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"PRCurve\")\n",
    "\n",
    "\n",
    "float, default\n",
    "\n",
    "writer.add_pr_curve('Wine_PR', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3-xyVqLH_qr"
   },
   "source": [
    "#То же самое для аудио- данных + Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i9W1LaBWAZS"
   },
   "source": [
    "**Загрузка даннных.**\n",
    "\n",
    "В Pytorch есть три библиотеки для работы с разными типами данных:\n",
    "\n",
    "[torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "[torchaudio](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html)\n",
    "\n",
    "\n",
    "Для загрузки данных  используются классы [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) и [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). \n",
    "\n",
    "Они предоставляют единый интерфейс для доступа к данным различных типов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgYqyAgm2uF4"
   },
   "source": [
    "# Пример загрузки аудио."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5724,
     "status": "ok",
     "timestamp": 1607540000307,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "uJUjZX_yboQk",
    "outputId": "33fcb7b0-c907-4b27-e007-50a6c42eb272"
   },
   "outputs": [],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raahLh_R2k0p"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torchaudio\n",
    "speech_commands_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"sample_data\",download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-au7NPU92kkr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382,
     "referenced_widgets": [
      "381bc4eaf8b6472e8f500e8a90d9d65f",
      "40528b254afe40078555fde5f35998ff",
      "9e8cb0fb5fe7497bb4490c04c60a46e4",
      "c39f4131ce6544c6ab8e8ca9c5e87890",
      "cd8cc5ad405d4d6aa043bfd357aab7a7",
      "e1fdeb2a4f6b4e279fc3636dd998796d",
      "197ebd6b42d543d78f16b62553f309f7",
      "64e50b2e9a2e4eadadb1e8368f9a5bfa"
     ]
    },
    "executionInfo": {
     "elapsed": 96046,
     "status": "ok",
     "timestamp": 1607540117804,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "F6I2XhCjV7dr",
    "outputId": "514589ab-10b5-445d-d907-08b40beab4da"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Speech Commands:  A Dataset for Limited-Vocabulary SpeechRecognition\n",
    "# https://arxiv.org/pdf/1804.03209.pdf\n",
    "# https://pytorch.org/audio/stable/datasets.html#speechcommands\n",
    "\n",
    "\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(speech_commands_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for sample in data_loader:\n",
    "  # Dataloader must return a batch but somtime single item can be returned :(  \n",
    "  waveform,  sample_rate, labels = sample[:3]\n",
    "  print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform.shape, sample_rate, labels))\n",
    "\n",
    "  plt.figure()\n",
    "  plt.title(f\"Label: {labels[0]}\")\n",
    "  plt.plot(waveform[0].t().numpy())\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1607546838984,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "aTtFK3r126Pc",
    "outputId": "c803ac2b-6768-4b59-fd65-be465a0c56bb"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(waveform[0].numpy(), rate=sample_rate.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 61
    },
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1607546910221,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "5tUtRUdlQo-3",
    "outputId": "48378f96-308a-4c7e-c5b0-8cfc8bc8bc60"
   },
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "transformed = transform(waveform[0])\n",
    "\n",
    "ipd.Audio(transformed.numpy(), rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXJCwh7f2hOT"
   },
   "outputs": [],
   "source": [
    "Включить примеры рассчета метрик!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmK6yV3x2SKH"
   },
   "source": [
    "Метод K- ближайших соседей на CIFAR10. \n",
    "Если рассматрить его по шагам, то нужно альтернативное задание на практическую часть семинара. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPxZSlv43x_H"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### 1.5.2Метод ближайшего соседа\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/knn.png\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-25.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-26.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-27.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-28.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBjcvp9OHqX0"
   },
   "source": [
    "# Практическая часть:\n",
    "\n",
    "https://colab.research.google.com/drive/1EPP7XSydB_k-g3h73He67k7mH9pPqUFS?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnYXdaJb09Sg"
   },
   "outputs": [],
   "source": [
    "K- Nearest Neighbor\n",
    "\n",
    "https://colab.research.google.com/drive/1_5tGxAoxrWulPmwK2Ht9BHGsS-EpxVo0?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "736ef147bda8415d8c8731db34732728",
      "0fc5e61f821c4be28c616be367ee06e9",
      "c433b2e07f75435c9fad22b9eaa586aa",
      "d4bf3a28a428414f81187b851de2c61f",
      "d4f71da5a2b44d348d742a216d9f2244",
      "61b496e597ab4d3eafa01c8d83d17e52",
      "db0df8d36f9a4bc3b853f44ccd25f810",
      "5165ebe17bd44482a548a6edb6813507"
     ]
    },
    "executionInfo": {
     "elapsed": 16650,
     "status": "ok",
     "timestamp": 1606334820604,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "S-h-9uOw_W1-",
    "outputId": "fcc50d87-3d89-4bbb-86a8-6bdcbb7da0ba"
   },
   "outputs": [],
   "source": [
    "# Загрузка изображений\n",
    "\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "transform = None\n",
    "\n",
    "trainset = datasets.CIFAR10(\"content\", train=True, transform = transform ,  download=True)\n",
    "testset = datasets.CIFAR10(\"content\", train = False, transform = transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 1625,
     "status": "ok",
     "timestamp": 1606335206995,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "MhRzzRB6_8xV",
    "outputId": "58529214-bf92-4d7e-e4af-e46a156981c2"
   },
   "outputs": [],
   "source": [
    "# Выведем несколько картинок вместе с метками\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# Загрузим названия классов. Исключительно для наглядности, для обучения модели они не нужны.\n",
    "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\n",
    "  cifar_meta = pickle.load(infile)\n",
    "labels = cifar_meta['label_names']\n",
    "\n",
    "# В тензоре изображения хранятьтся в формате СxHxW \n",
    "# Что бы вывести их стадтартным способом нужно преобразовать их к HxWxC\n",
    "def to_img(tens):\n",
    "    # И денормализовать если перед этим происходила нормализация\n",
    "    # img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = tens.numpy()\n",
    "    retnp.pose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "  image, class_num = trainset[j]\n",
    "  plt.subplot(1, 10 ,j+1)\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')  \n",
    "\n",
    "  plt.title(labels[class_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYqGpeY7C4XP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import random \n",
    "\n",
    "\n",
    "class NearestNeighbor:\n",
    "  def __init__(self):\n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "\n",
    "  def train(self,x,y):\n",
    "    self.train_data = torch.vstack((self.train_data,x)) if self.train_data != None else x\n",
    "    self.train_labels = torch.hstack((self.train_labels,y)) if self.train_labels != None else y\n",
    "   \n",
    "  \n",
    "  def predict(self,x):\n",
    "    # x.shape 3x32x32\n",
    "    diff = self.train_data - x\n",
    "    abs = torch.abs(diff)\n",
    "    distances = torch.sum(abs,dim = (1,2,3)) # Axis 0 it's a row num in image list \n",
    "    return self.train_labels[torch.argmin(distances)]\n",
    "\n",
    "model = NearestNeighbor()\n",
    "\n",
    "\n",
    "trainset.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "train_dataloder = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "\n",
    "\n",
    "for img_batch, labels_batch in train_dataloder:\n",
    "  model.train(img_batch, labels_batch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 5967,
     "status": "ok",
     "timestamp": 1606339059422,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "vge98_CHQPTd",
    "outputId": "e51687a3-8145-471d-c8bc-81fc2cb139a7"
   },
   "outputs": [],
   "source": [
    "# Проверим работу модели на нескольких изображениях из тестового набора данных\n",
    "  \n",
    "testset.transform = transforms.Compose([ transforms.ToTensor(),  ])\n",
    "test_dataloder = DataLoader(testset, batch_size=10 ,shuffle=True)\n",
    "img_batch, class_num_batch = next(iter(test_dataloder))\n",
    "#print(test_batch.shape)\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "  label_ind = model.predict(img_batch[j])\n",
    "\n",
    "  img = img_batch[j].permute(1,2,0).numpy()*255  \n",
    "  plt.subplot(1, 10,j+1)\n",
    "  plt.imshow(img.astype(int))\n",
    "  plt.axis('off')\n",
    "\n",
    "  plt.title(labels[int(label_ind)])\n",
    "  #j += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ac_JzpiZRkl3"
   },
   "outputs": [],
   "source": [
    "# Посчтитать Accuracy\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def validate(model,x_test,y_test):\n",
    "  y_predicted = []\n",
    "  for i, sample in enumerate(x_test):\n",
    "    index = model.predict(sample)\n",
    "    y_predicted.append(index) \n",
    "  return accuracy_score(y_test, y_predicted)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testset.transform = transforms.Compose([ transforms.ToTensor(),  ])\n",
    "test_dataloder = DataLoader(testset, batch_size=1024 ,shuffle=True)\n",
    "\n",
    "start = time.perf_counter()\n",
    "for img_batch, class_num_batch in test_dataloder:\n",
    "  accuracy = validate(model,img_batch,class_num_batch)   \n",
    "  tm = time.perf_counter() - start\n",
    "  total = img_batch.shape[0]\n",
    "  print(\"Accuracy {:.2f} Train {:d} /test {:d} in {:.1f} sec. speed {:.2f} samples per second.\".format(accuracy,total,total,tm,total/tm,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01wgF3h7T9nc"
   },
   "outputs": [],
   "source": [
    "# Implementation of KNN (optionally)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class KNearestNeighbor(NearestNeighbor):\n",
    "  def __init__(self,k):\n",
    "    self.k = k\n",
    "    pass\n",
    "  \n",
    "  def predict(self,x):\n",
    "    distances = np.sum(np.abs(self.train_data - x),axis = 1)\n",
    "    sorted_distance_indexes = np.argsort(distances)\n",
    "    k_nearest_images = sorted_distance_indexes[:self.k]\n",
    "    most_common = Counter(self.train_labels[k_nearest_images]).most_common()\n",
    "    return most_common[0][0]\n",
    "\n",
    "knn = KNearestNeighbor(7)\n",
    "knn.train( x_train,y_train)\n",
    "validate(knn,x_test,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PCVXf2iUKNp"
   },
   "outputs": [],
   "source": [
    "# Здесь посчитать precision и recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9pqYpu5lIc7"
   },
   "source": [
    "#Блок про локальную настройку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vv9Jyhv6NM1"
   },
   "source": [
    "# Чулан"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12191,
     "status": "ok",
     "timestamp": 1606045672331,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "ixgpb2CXxBdH",
    "outputId": "56ab75da-becf-41ac-cf68-ec89147dcf62"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/brinkar/real-world-machine-learning.git\n",
    "\n",
    "\n",
    "#Примеры из кники Х. Бринк \"Real world machine learning\"\n",
    "https://github.com/brinkar/real-world-machine-learning/blob/master/Chapter%203%20-%20Modeling%20and%20prediction.ipynb\n",
    "\n",
    "# Либо на toy-датасетах из scikit-learn что более легко воспроизводимо \n",
    "https://scikit-learn.org/stable/datasets/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k21OAuXuOSS4"
   },
   "outputs": [],
   "source": [
    "! pip install torchtext spacy\n",
    "!python -m spacy download en\n",
    "!python -m spacy download de\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEnxK3LQKbu-"
   },
   "outputs": [],
   "source": [
    "# Пример загрузки текста \n",
    "\n",
    "# https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n",
    "# https://pytorch.org/text/stable/datasets.html#multi30k\n",
    "# Документация с пояснениями\n",
    "# https://dzlab.github.io/dltips/en/pytorch/basic-nlp-pytorch-text/\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "#multi30k = torchtext.datasets.Multi30k(\"sample_data\", exts, fields, **kwargs)\n",
    "\n",
    "SRC = Field(tokenize = \"spacy\", tokenizer_language=\"de\", init_token = '<sos>', eos_token = '<eos>', lower = True)\n",
    "\n",
    "TRG = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language=\"en\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),fields = (SRC, TRG))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
