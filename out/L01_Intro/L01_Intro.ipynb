{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BPcyQRmXq8I"
   },
   "source": [
    "# 1.1 Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRJ-JLXkb2PN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHiB-TsSVCcV"
   },
   "source": [
    "\n",
    "### 1.1.1 Место глубокого обучения и нейронных сетей в ИИ\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro1.png\" >\n",
    "\n",
    "Существует множество разных определений, однако большая часть из них завязана на человеко-машинном взаимодействии, то есть это алгоритмы или методы, которые либо имитируют поведение людей, либо позволяют машине вести себя аналогично людям (то есть проявлять некоторое интеллектуальное-разумное поведение). Область ИИ не ограничивалась исключительно машинным обучением, которое состоит из обучения на примерах. В ИИ входит целый ряд алгоритмов, например многоагентные системы (расшифровка) или базы знаний, в которых люди создают связи между разными понятиями.\n",
    "\n",
    "**Искусственный интеллект (AI/ИИ)**  ~= область ИТ/Computer science связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение(ML)** - подраздел ИИ связанный с обучением на данных, он не единственный. Например базы знаний или многоагентные системы также относят к разделам ИИ. \n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** ~= Многослойная нейросеть (MLP = multi layer perceptron)\n",
    "\n",
    "Однако сейчас мы рассмотрим более узкую область, связанную с МЛ. Модели, которые имеют несколько слоев называются глубокими или нейросетевыми. Хотя если мы возьмем один слой такой модели (например линейный классификатор, он же перцептрон), он перестанет быть глубокой моделью, хотя по факту он и является простейшей нейросетью!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6uYWy01di2p"
   },
   "source": [
    "### 1.1.2 Области применения DL\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/Intro2.jpg\" >\n",
    "\n",
    "В последнее время именно такого рода модели показываю высокую эффективность в тех областях, в которых влияние человека казалось превалирующим. В частности это человеко-компьютерное зрение (Computer Vision, CV), распознавание естественного языка (NLP, извлечение смысла, машинный перевод) и речи. В рамка курса мы рассмотрим как эта область может применяться на практических задачах и моделях, их решающих. Также мы познакомимся с результатами самых современных исследований по теме. \n",
    "\n",
    "В данном курсе мы подробно рассмотрим технологии DL применяющиеся в этих областях.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TiPYPVaeNiZ"
   },
   "source": [
    "### 1.1.3 Связь DL с наукой\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro3.png\" >\n",
    "\n",
    "Помимо прикладных задач существуют еще и научные исследования, результаты которых до известной степени непредсказуемы. Несльзя исключить что он появятся в областях где технологии DL до сих пор активно не использовались.\n",
    "\n",
    " Поддержка такого рода исследований есть основная задача курса нашего курса.\n",
    "\n",
    "\n",
    " Вариант2:\n",
    "\n",
    " Мы видим что NN уже нашли применение в множестве массовых(типовых) задач которые нас окружают.\n",
    "\n",
    "Однако каждая научная работа индивидуальна, в этом состоит сложность: только автор понимает как обрабатываются данные в его предметной области и как следует оценить результат.\n",
    "\n",
    "Но не всегда ученые особенно из естественных или гуманитарных областей готовы самостоятельно применить ML к объекту своих исследований.\n",
    "Поэтому мы здесь ...\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzTmT5m5e-hN"
   },
   "source": [
    "# 1.2 История глубокого обучения\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro4.png\" >\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro5.png\" >\n",
    "\n",
    "На изображении вы видите перцептрон - по сути первую нейросеть, которая появилась более полувека назад. Это однослойная нейронная сеть, которая сейчас не отнесли бы к моделям глубокого обучения. \n",
    "\n",
    "Перцептрон состоит из трёх типов элементов, а именно: поступающие от датчиков **сигналы** передаются **ассоциативным элементам**, а затем **реагирующим элементам**. Таким образом, перцептроны позволяют создать набор «ассоциаций» между входными стимулами и необходимой реакцией на выходе. \n",
    "В биологическом плане это соответствует преобразованию, например, зрительной информации в физиологический ответ от двигательных нейронов. \n",
    "\n",
    "Суть модели достаточно простая: на вход подаются данные и каждому присваивается вес, на выходе суммируются, далее применяется (пороговая) функция активации. Грубая аналогия - нейрон человеческого мозга, который работает по такому же принципу. \n",
    "На тот момент это стало прорывом и захватило великие умы. Был построен суперкомпьютер, который занимал несколько помещений.\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro61.png\" >\n",
    "\n",
    "Однако уже через несколько лет было доказано, что перцептрон не может воспроизвести ряд простых функций, например функцию **xor**, продемонстрированую в таблице. \n",
    "\n",
    "После этого открытия интерес к нейросетям резко падал и они находились в забвении. По сути, даже опубликовать статью по данной теме было затруднительно.\n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro6.png\" >\n",
    "\n",
    "Одной из важнейших работ связанных с глубоким обучением является эксперимент американских биологов из Гарварда. В 1959 были изучены реакции определенных участков кошачьего мозга на определенные простые визуальные стимулы. \n",
    "Как и большая часть открытий, это выяснилось абсолютно случайно. \n",
    "\n",
    "В мозг кошке был вживлен электрод чтобы определить на какой рисунок будет реакция. Однако стоит вспомнить, что в то время слайды переключались последовательным движением и именно на это движение случилась реакция. Как только менялся слайд и по экрану проходила граница затвора, по сути простая прямая линия, реакция передавалась и записывалась.\n",
    "\n",
    "После ряда экспериментов выяснилось, что существуют клетки, реагирующие на простые формы (линии и углы), на движение и движение в определенном направлении или определенной формы. \n",
    "\n",
    "Слои этих клеток образуют определенного рода иерархию и именно эта идея лежит в основе концепции нейросетевых методов.  \n",
    "\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro7.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V-s9vYSW21U"
   },
   "source": [
    "### 1.2.2 Победа нейросети AlexNet на соревновании ImageNet в 2012\n",
    "\n",
    "<img src =\"http://edunet.kea.su/repo/src/L01_Intro/img/mp/intro8.png\" >\n",
    "\n",
    "### 1.2.3 ImageNet: Large Scale Visual Recognition Challenge (ILSVRC)\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro5.png\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUEkABb2lllH"
   },
   "source": [
    "## 1.3 Области применения DL в настоящее время\n",
    "\n",
    "### 1.3.1  Робототехника\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro6.png\" >\n",
    "Беспилотные автомобили Self-Driving Car и дроны\n",
    "Промышленные и бытовые роботы.\n",
    "\n",
    "### 1.3.2 Безопасность\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro7.png\" >\n",
    "\n",
    "\n",
    "Видеоаналитика, контроль доступа, распознавние лиц, номеров.\n",
    "\n",
    "\n",
    "### 1.3.3 Интернет и дополненная реальность\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro8.png\" >\n",
    "\n",
    "Поиск в том числе семантический. Анализ контента, в том числе визуального. Машинный перевод. Распознавание речи.\n",
    "\n",
    "\n",
    "\n",
    "### 1.3.4 Медицина\n",
    "\n",
    "- добавить примеров\n",
    "\n",
    "### 1.3.5 Применение DL в научных исследованиях\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro9.png\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro10.png\" >\n",
    "\n",
    "\n",
    "\n",
    "### 1.3.7 Причины успехов технологий на основе DL\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro11.png\" >\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXDX8IY8xw_3"
   },
   "source": [
    "## 1.4 Задачи решаемые при помощи машинного обучения\n",
    "\n",
    "### 1.4.1 Извлечение закономерностей\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro13.png\" >\n",
    "\n",
    "Ученый многократно наблюдает за ходом процесса и делает обобщения.\n",
    "\n",
    "Результатом такой работы является модель описывающая некоторые процессы реального мира.\n",
    "\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro14.png\" >\n",
    "\n",
    "ML - технология которая позволяет выявлять закономерности в данных и обобщать их. \n",
    "\n",
    "Результатом обучения такой модели является набор весов. \n",
    "\n",
    "По сути это набор коэффициентов для некоторого математического выражения.\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro15.png\" >\n",
    "\n",
    "Законы Ньютоны не сформулированны для яблок.\n",
    "Для описания закономерностей в науке используются абстракции:  сила, масса ускорение которыми описываются реальные объекты.\n",
    "\n",
    "Данные для ML моделей тоже должны быть подготовлены. Типичная форма такой абстракции вектор чисел.\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro16.png\" >\n",
    "\n",
    "Второй частью процесса обучения является оценка результата. \n",
    "\n",
    "Полученный результат сравнивают с эталонным  и если разница велика - корректируют модель.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEk8ruzC1BRb"
   },
   "source": [
    "## Пример\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro17.png\" >\n",
    "\n",
    "Нужно посчитать количество шагов используя показания акселерометра встроенного в шагомер. \n",
    "\n",
    "#### Вариант №1\n",
    "\n",
    "Написать программу вида:\n",
    "\n",
    "if x[i] > x[i - k] and y[i] > y[i - k] and ...\n",
    "  ....\n",
    "else:\n",
    "  ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDxLDZPo1rjl"
   },
   "source": [
    "\n",
    "Вариант №2\n",
    "\n",
    "Обучить модель\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro18.png\" >\n",
    "\n",
    "При этом можно не занать ничего о природе сигналов. Важно лиш собрать достаточное количество данных и разметить их.\n",
    "Разметка в данном случае будет заключаться в с боре информации о том сколько фактически шагов сделал человек.\n",
    "\n",
    "## 1.4.3 Базовые задачи\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro19.png\" >\n",
    "\n",
    "## 1.4.3 Виды данных\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro20.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o346mPzulsAV"
   },
   "source": [
    "\n",
    "#1.4.4 Оценка результата\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-17.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-18.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-19.jpg\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/accuracy.png\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-21.jpg\" >\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DukPy4wh1gBW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDG77F4f4zzx"
   },
   "source": [
    "## 1.5 Примеры задач решаемых при помощи методов машинного обучения\n",
    "\n",
    "\n",
    "Рассмотрим примеры решения задач классификации и линейной регресии на различных типах данных.\n",
    "\n",
    "\n",
    "Будем использовать библиотеки:\n",
    "* numpy\n",
    "* [skilearn](https://scikit-learn.org/stable/) - 'toy' датасеты, ML алгорытмы \n",
    "* [pandas](https://pandas.pydata.org/) - удобная работа с табличными данными\n",
    "\n",
    "познакомимся с инструментами:\n",
    "\n",
    "* **Pytorch** \n",
    "* **Tensorboard**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLlvxAHKxESh"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6y12nR9YpxU"
   },
   "source": [
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-16.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9wREYtJ6-6w"
   },
   "source": [
    "### 1.5.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMd2GsRfMmG4"
   },
   "outputs": [],
   "source": [
    "# Классификация вин \n",
    "# Используем библиотеку sklearn: https://scikit-learn.org/stable/ \n",
    "\n",
    "import sklearn \n",
    "from sklearn.datasets import load_wine\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "# Загрузка датасета\n",
    "data = load_wine(return_X_y = True) # Так же можно получить данные в Bunch(словарь) или pandas DataFrame\n",
    "\n",
    "features = data[0] # Массив 178x13 178 бутылок у каждой 13 признаков\n",
    "class_labels = data[1] # Массив из 178 элементов каждый элемент это число обозначающее класс к которому относиться данная бутылка : 0,1 2  \n",
    "print(\"Данные\",features.shape)\n",
    "print(\"Номер класса\",class_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tohStSfdt-NE"
   },
   "source": [
    "### 1.5.2 Визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O4BBbqQJSNg"
   },
   "outputs": [],
   "source": [
    "# Подключим библиотеку для работы с табличнымии данными: https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "data_bunch = load_wine(return_X_y = False)\n",
    "print(data_bunch.keys())\n",
    "\"\"\"\n",
    "  Если параметр return_X_y == False\n",
    "  Данные в объекте Bunch: https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch \n",
    "  По сути это словарь.\n",
    "  Что бы отобразить данные в виде таблицы преобразуем их в формат pandas.DataFrame\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame(data_bunch.data, columns=data_bunch.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olpH1dK3Nc-p"
   },
   "source": [
    "Каждая строка в таблице может быть интерпретированна как вектор из 13 элементов. Можно интерпретировать такой вектор как координаты точки в 13 - мерном пространстве. Именно с таким представлением работают большинство алгоритмов машинного обучения. \n",
    "\n",
    "Визуализировать 13-мерное пространство не получиться :(. \n",
    "\n",
    "Но можно визуализировать проекцию данных в 3-х мерное пространство. Для этого воспользуемся инструментом projector из tensorboard\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80kpga5uVjw8"
   },
   "outputs": [],
   "source": [
    "# Вспомогательный метод для запуска Tensorboard в Colab\n",
    "\n",
    "# Fix: https://stackoverflow.com/questions/60730544/tensorboard-colab-tensorflow-api-v1-io-gfile-has-no-attribute-get-filesystem\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Запуск Tensorboard в Colab\n",
    "def reinit_tensorboard(clear_log = True):\n",
    "  # Лог-файлы читаются из этого каталога: \n",
    "  logs_base_dir = \"runs\"\n",
    "  if clear_log:\n",
    "    # Очистка логов\n",
    "    #!rm -rfv {logs_base_dir}/*\n",
    "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
    "    os.makedirs(logs_base_dir, exist_ok=True)\n",
    "  # Магия Colab\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtb8It_Rv3e1"
   },
   "source": [
    "После загрузки Tensorboard измените значение опции \"Color by\" на \"label 3 colors\" что бы объекты принадлежащие к разным классам отображались разными цветами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxCxSnsISXvy"
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "np_f = numpy.array(features)\n",
    "writer.add_embedding(np_f, metadata=class_labels )\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjktILYlY99H"
   },
   "source": [
    "Рассказ про PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qM3rjfEObMd"
   },
   "source": [
    "Видно что объекты классов 1 и 2 линейно не разделимы в 2-х измерениях. По этой причине так популярен переход к пространствам большей размерности. \n",
    "\n",
    "Обратите внимание что данные центрированны около нуля - это результат нормализации которой они подверглись в Tensorboard.\n",
    "\n",
    "Нам тоже потребуется нормализовыть данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NWTf-ZPKXc"
   },
   "source": [
    "## 1.5.3 Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udGzAucjZIUr"
   },
   "source": [
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/v2/min_max.png\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/v2/norm_distr.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4fJFRLGPQaC"
   },
   "outputs": [],
   "source": [
    "# Сделаем это средствами pytorch\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "\n",
    "\n",
    "# Отобразим значения двух параметров значения которых отличаются примерно на порядок\n",
    "f_names = data_bunch.feature_names\n",
    "for i, feature in enumerate(features):\n",
    "  writer.add_scalars(\"Raw_2_par\",{ \n",
    "      f_names[1]:feature[1], # malic_acid\n",
    "      f_names[3]:feature[3],  # alcalinity_of_ash\n",
    "     } ) \n",
    "\n",
    "# Добавим еще один значения которого отличается от второго на 2 порядка\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "  writer.add_scalars(\"Raw_3par\",{ \n",
    "                                     f_names[1]:feature[1], # malic_acid\n",
    "                                     f_names[3]:feature[3],  # alcalinity_of_ash\n",
    "                                     f_names[12]:feature[12] # proline \n",
    "                                     } ) \n",
    "\n",
    "# Добавим гистограмму для сырых данных.\n",
    "writer.add_histogram(\"1.Raw\" , features[:,3])\n",
    "writer.add_histogram(\"1.Raw\" , features[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# Преобразовали данные к torch.Tensor \n",
    "tensor_f = torch.tensor(features)\n",
    "\n",
    "# Mini-Max  нормализация\n",
    "\n",
    "# torch.min и torch.max возвращают кортежи (values, indexes)\n",
    "# https://pytorch.org/docs/stable/generated/torch.min.html#torch.min\n",
    "\n",
    "min_values, _  = tensor_f.min(dim=1,keepdim=True)  # shape = (178,1)\n",
    "max_values, _  = tensor_f.max(dim=1,keepdim=True)  # shape = (178,1)\n",
    "\n",
    "# Вычитаем минимальное значение\n",
    "min_max_centered = tensor_f - min_values\n",
    "# Делим на среднее\n",
    "min_max_normalized =  min_max_centered / (max_values - min_values)\n",
    "\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,3])\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,1])\n",
    "\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,3])\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,1])\n",
    "\n",
    "# Стандартизация / Z-нормализация\n",
    "\n",
    "# Вычитаем среднее\n",
    "centered = tensor_f - tensor_f.mean(dim=0)\n",
    "# Разделим на стандартное отклонение\n",
    "normalized = centered / tensor_f.std(dim=0)\n",
    "\n",
    "# Добавим гистограмму для стандартизированных данных в Tensorboard\n",
    "writer.add_histogram(\"3.Centered\" , centered[:,3])\n",
    "writer.add_histogram(\"3.Centered\" , centered[:,1])\n",
    "\n",
    "writer.add_histogram(\"3.Normalized\" , normalized[:,3])\n",
    "writer.add_histogram(\"3.Normalized\" , normalized[:,1])\n",
    "\n",
    "\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , features[:,1])\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , min_max_normalized[:,1])\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , normalized[:,1])\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9Y5GHEqnLp9"
   },
   "source": [
    "## 1. После загрузки Tensorboard выберите пункт меню \"SCALARS\"\n",
    "затем 'Horizontal Axis' = Relative\n",
    "\n",
    "Значения в разных масштабах - несравнимы между собой\n",
    "\n",
    "## 2. выберите пункт меню \"HISTOGRAMS\"\n",
    "затем Offset time axis = WALL или RELATIVE\n",
    "\n",
    "Наглядное приемущество Стандартизации перед max-min нормализацией\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj3nWSjhmtnJ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf-95rOeHYat"
   },
   "source": [
    "### 1.5.4 Обучение\n",
    "\n",
    "Базовая документация\n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "Пример использования SVM классификатора\n",
    "https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqs6K8JZwh1u"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, class_labels, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"X_test\",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-dQz4BpVrKK"
   },
   "source": [
    "##№ 1.5.5 Обучим модель и посчитаем точность (Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irm2wG821UlR"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Создаем модель\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "# Обучаем модель на части данных\n",
    "lin_clf.fit(X_train, y_train)\n",
    "\n",
    "# Получаем предсказания\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "print(\"y_pred\",y_pred.shape)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3-xyVqLH_qr"
   },
   "source": [
    "#Аналогичным образом можно работать с различными типами данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i9W1LaBWAZS"
   },
   "source": [
    "**Загрузка даннных.**\n",
    "\n",
    "В Pytorch есть три библиотеки для работы с разными типами данных:\n",
    "\n",
    "[torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "[torchaudio](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html)\n",
    "\n",
    "\n",
    "Для загрузки данных  используются классы [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) и [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). \n",
    "\n",
    "Они предоставляют единый интерфейс для доступа к данным различных типов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgYqyAgm2uF4"
   },
   "source": [
    "# Пример загрузки аудио средствами Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOlzSR45IaLj"
   },
   "source": [
    "Установим библиотеку torch.audio она не входит в список пакетов доступных в colab по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJUjZX_yboQk"
   },
   "outputs": [],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDI5LRLiIsWI"
   },
   "source": [
    "##Загрузим датасет\n",
    "\n",
    "Speech Commands:  A Dataset for Limited-Vocabulary SpeechRecognition\n",
    "\n",
    "https://arxiv.org/pdf/1804.03209.pdf\n",
    "\n",
    "https://pytorch.org/audio/stable/datasets.html#speechcommands\n",
    "\n",
    "Данные будут распакованны в папку sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raahLh_R2k0p"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "speech_commands_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"sample_data\",download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oS7IVuiGOP_"
   },
   "source": [
    "\n",
    "Объект speech_commands_dataset - это экземпляр класса который является наследником  [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html) это означает что в нем реализованы методы \n",
    "* __getitem__ \n",
    "* __len__\n",
    "\n",
    "Благодаря этому, мы можем узнать количество элементов или получить произвольный элемент данных обращаясь к объекту класса Dataset  так же как к обычному списку в python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktqQtSLtIUIu"
   },
   "outputs": [],
   "source": [
    "print(\"Количество элементов {} \".format(len(speech_commands_dataset)))\n",
    "print(\"Первый элемент\",speech_commands_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACQxVzNiH00E"
   },
   "source": [
    "## Что представляет из себя элемент аудио - данных?\n",
    "Обратимся к документации: https://pytorch.org/audio/stable/datasets.html#speechcommands\n",
    "\n",
    "... returns:\n",
    "\n",
    "    (waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "utterance_number - номер повтора. Больше нуля если один и тот же человек проговаривает одну и ту же фразу несколько раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0tH4UF8KKiC"
   },
   "outputs": [],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = speech_commands_dataset[0]\n",
    "print(\"Waveform: {}\\nSample rate: {}\\nLabel: {} \\nSpeaker_id: {} \\nutterance_number: {}\".format(waveform.shape, sample_rate, label,speaker_id,utterance_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1meIJy9PNo7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjHSl83yNbxV"
   },
   "source": [
    "\n",
    "Размеры тензора waveform:\n",
    "    \n",
    "    [1, 16000] \n",
    "\n",
    "1- количество каналов, 16000 количество измерений в секунду\n",
    "\n",
    "Если частота дискретизации(sample_rate) равна 16000 то этот фрагмент занимает ровно 1 секунду \n",
    "\n",
    "Визуализируем их:\n",
    "x - время\n",
    "y - давление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjgzXIOQNk27"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(type(waveform))\n",
    "plt.figure()\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.plot(waveform.t().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYcb2s93N9gT"
   },
   "source": [
    "# Озвучим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpKCYA0-OGSL"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv2IyIdiVdTZ"
   },
   "source": [
    "## Итерация по датасету.\n",
    "\n",
    "Для начала запустим простую проверку: убедимся что все записи одинаковой длины.\n",
    "\n",
    "### Почему это важно\n",
    "\n",
    "* list\n",
    "* numpy - массив\n",
    "* torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AstmNrPNWLvv"
   },
   "source": [
    "Проверим что все записи имеют одинаковую длину. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsCRUVh1Wjrv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def_length = 16000\n",
    "for i, sample in enumerate(speech_commands_dataset):\n",
    "  waveform, sample_rate, label, speaker_id, utterance_number = sample\n",
    "  if def_length != waveform.shape[1]: # [1, 16000]\n",
    "    print(i)\n",
    "    print(\"Waveform: {}\\nSample rate: {}\\nLabel: {} \\nSpeaker_id: {} \\nutterance_number: {}\".format(waveform.shape, sample_rate, label,speaker_id,utterance_number))\n",
    "    break\n",
    "  if not i% 10000 and i > 0 :\n",
    "    print(f\"Processed {i} objects\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yed0_9fTZKJT"
   },
   "source": [
    "Если не все элементы будут иметь различную длину мы не сможем их сравнивать. И даже технически поместить в один массив. Необходомо их выровнять. Так как многие записи начинаются и заканчиваются тишиной, то просто дополним их нулями.\n",
    "Для этого применим концепцию трансформаций (transform) которая широко применяется в Pytorch и встраивается во многие датасеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfekd5aSbd9j"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "class PadWaveform(torch.nn.Module):\n",
    "  def __init__(self, desired_size = 16000):\n",
    "    self.desired_size = desired_size\n",
    "    super().__init__()\n",
    "\n",
    "  # in nn.Module forward method called inside __call__ method\n",
    "\n",
    "  def forward(self, waveform):\n",
    "    if waveform.shape[1] < self.desired_size:\n",
    "      diff = self.desired_size - waveform.shape[1]\n",
    "      pad_left = diff // 2\n",
    "      pad_right = diff - pad_left\n",
    "      return torch.nn.functional.pad(waveform,[pad_left, pad_right])\n",
    "    else:\n",
    "      return waveform\n",
    "\n",
    "class customSpeechCommandsDataset(torchaudio.datasets.SPEECHCOMMANDS):\n",
    "  def __init__(self,transform,root = \"sample_data\"):\n",
    "    self.transform = transform\n",
    "    super().__init__(root)\n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self,n):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    transformed_waveform = self.transform(waveform)\n",
    "    return (transformed_waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform = torch.nn.Sequential(PadWaveform(16000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usKlStbZgC7K"
   },
   "source": [
    "Теперь можно добавлять дополнительные трансформации. Например уменьшить частоту дискретизации (sample_rate) что бы данные занимали меньше места.\n",
    "\n",
    "Для этого в модуле:\n",
    "[torchaudio.transforms](https://pytorch.org/audio/stable/transforms.html#resample)  уже есть готовая трансформация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCXvbnpDgx3l"
   },
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform = torch.nn.Sequential(\n",
    "    Resample(16000,8000),\n",
    "    PadWaveform(8000))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Pf6OugkhzVy"
   },
   "source": [
    "### Визуализируем данные\n",
    "\n",
    "Датасет в архиве занимает > 2Gb и это далеко не предел. Поэтому работать с ним будем по частям. \n",
    "\n",
    "Для этой задачи в pytorch используется класс Dataloader. Одной из его функций является пакетная(batch) загрузка данных. Особенно она будет полезна при обучении. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sI9S3rsiKj2"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(speech_commands_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "writer = SummaryWriter(comment = \"commands\")\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "  print(waveforms.shape)\n",
    "  print(labels)\n",
    "  # Данные преобразовались в тензоры\n",
    "  # Убираем 1-е измерение оставшееся от канала\n",
    "  writer.add_embedding(torch.squeeze(waveforms), metadata=labels )\n",
    "  break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dPYh7B_lr3G"
   },
   "source": [
    "##Запустим Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q_NKnewlpen"
   },
   "outputs": [],
   "source": [
    "reinit_tensorboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYVESERLqLRp"
   },
   "source": [
    "### Надо ли нормализовать эти данные?\n",
    "\n",
    "Загрузим значения 2-х произвольных признаков в Tensorboard b проверим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90ZuZCwRn6ta"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment = \"commands\")\n",
    "for i, batch in enumerate(data_loader):\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,100])\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,200])\n",
    "  break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ci3HGTqei5"
   },
   "source": [
    "Как видно из гистограммы, данные уже центрированны вкруг нуля и имеют один масшаб. Отчасти это связанно с тем что что они имеют одну и ту же природу, отчасти с форматом хранения звука. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB3k4rvZyYpC"
   },
   "source": [
    "### Обучение\n",
    "\n",
    "Для обучения потребуются метки. Попутно избавимся от лишнего. Создадим очередную трансформацию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4WGKr9gyq-c"
   },
   "outputs": [],
   "source": [
    "class ClassName2Num(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, waveform):\n",
    "    if waveform.shape[1] < self.desired_size:\n",
    "      diff = self.desired_size - waveform.shape[1]\n",
    "      pad_left = diff // 2\n",
    "      pad_right = diff - pad_left\n",
    "      return torch.nn.functional.pad(waveform,[pad_left, pad_right])\n",
    "    else:\n",
    "      return waveform\n",
    "\n",
    "class customSpeechCommandsDatasetFinal(customSpeechCommandsDataset):\n",
    "  def __init__(self,transform = torch.nn.Sequential(),root = \"sample_data\"):\n",
    "    super().__init__(transform,root)\n",
    "    self.labels = self.get_labels()\n",
    "\n",
    "  def get_labels(self):\n",
    "    labels = set()\n",
    "    for i in range(len(self)):\n",
    "      item = super(customSpeechCommandsDataset,self).__getitem__(i)\n",
    "      labels.add(item[2])\n",
    "    return sorted(list(labels)) \n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self,n):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    return (waveform[0],self.labels.index(label))\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDatasetFinal(transform = torch.nn.Sequential(\n",
    "    Resample(16000,8000),\n",
    "    PadWaveform(8000))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zB2PGDa965J5"
   },
   "outputs": [],
   "source": [
    "print(\"Classes\",speech_commands_dataset.labels)\n",
    "print(\"Classes num\",len(speech_commands_dataset.labels))\n",
    "\n",
    "wave, cls_num = speech_commands_dataset[0]\n",
    "print(wave.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_t-wlLr9yHU"
   },
   "source": [
    "Разделим данные на обучающую и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRpKWF6Z97XT"
   },
   "outputs": [],
   "source": [
    "total_len = len(speech_commands_dataset )\n",
    "print(\"Total length\",total_len)\n",
    "val_len = int(total_len*0.1)\n",
    "train_set, val_set = torch.utils.data.random_split(speech_commands_dataset, [total_len - val_len, val_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHPh5xGg1QII"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def validate(model):\n",
    "  data_loader = torch.utils.data.DataLoader(val_set, batch_size=1000, shuffle=False)\n",
    "  accuracy = []\n",
    "  for batch in data_loader:\n",
    "    waveforms, class_nums  = batch \n",
    "    y_pred = model.predict(waveforms)\n",
    "    accuracy.append(metrics.accuracy_score(class_nums, y_pred))\n",
    "  print(\"Accuracy:\",numpy.array(accuracy).mean())\n",
    "\n",
    "model = SGDClassifier(loss='log')  \n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=20000, shuffle=True)\n",
    "for batch in data_loader:\n",
    "  waveforms, class_nums  = batch\n",
    "  model.partial_fit(waveforms, class_nums,range(35))\n",
    "  validate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VH071PjLHTJp"
   },
   "source": [
    "Точность низкая. Для работы с этими данными нужна глубокая модель.\n",
    "С ее помощью можно получить точность >85%:\n",
    "\n",
    "[Speech Command Recognition with torchaudio](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/d87597d0062580c9ec699193e951e3f4/speech_command_recognition_with_torchaudio.ipynb#scrollTo=tl9K6deU4S10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aDSMa9v5PfK"
   },
   "source": [
    "## Место для рассказа про то чем строка в таблице принципиально отличается от аудиозаписи.\n",
    "\n",
    "\n",
    "....\n",
    "\n",
    "Вероятно тут стоит добавить несколько картинок.\n",
    "\n",
    "....\n",
    "\n",
    "\n",
    "* 1D - Таблица (столбцы не упорядоченны)\n",
    "* 2D - Аудио (данные упорядоченны по времени)\n",
    "* 3D - Монохромные изображения\n",
    "* 4D - Цветные изображения, монохромные 3-х мерные изображения (МРТ)\n",
    "* 5D - Видео, Воксельные изображения\n",
    "* 6D - 3-мерное видео "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W46TbNCa6VjW"
   },
   "source": [
    "#Работа с изображениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMwAHqiA7jc1"
   },
   "source": [
    "Загрузим датасет CIFAR-10. Он состоит из 60000 цветных изображений размером 32x32. На картинках объекты 10 классов.\n",
    "\n",
    "\n",
    " В отличие от torchaudio пакет torchvision при помощи которого загружается датасет входит в число предустановленных в colab.\n",
    "\n",
    "Датасеты из torcvision изначально поддерживают механизм transforms - нам не придется добавлять их вручную.\n",
    "\n",
    "Равно как и разбивку на тестовое и проверочные подмножества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-h-9uOw_W1-"
   },
   "outputs": [],
   "source": [
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainset = datasets.CIFAR10(\"content\", train=True,  download=True)\n",
    "valset = datasets.CIFAR10(\"content\", train = False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cA_6ApRo_39h"
   },
   "source": [
    "Выведем несколько картинок вместе с метками. Tensorboard имееи метод для вывода кртинок:\n",
    "[torchvision.utils.make_grid](https://pytorch.org/docs/stable/torchvision/utils.html)\n",
    "\n",
    "Однако он не поддерживает метки.\n",
    "\n",
    "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjcxcStpNDtAhWllYsKHa7XDLoQFjAAegQIBBAC&url=https%3A%2F%2Fdiscuss.pytorch.org%2Ft%2Fadd-label-captions-to-make-grid%2F42863&usg=AOvVaw19bkv0_Q8VQxD7WBZ3pFR_\n",
    "\n",
    "Поэтому воспользуемся matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhRzzRB6_8xV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# Загрузим названия классов. Исключительно для наглядности, для обучения модели они не нужны.\n",
    "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\n",
    "  cifar_meta = pickle.load(infile)\n",
    "labels = cifar_meta['label_names']\n",
    "\n",
    "for j in range(10):\n",
    "  image, class_num = trainset[j]\n",
    "  plt.subplot(1, 10 ,j+1)\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')  \n",
    "  plt.title(labels[class_num])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnIGtMngAzy_"
   },
   "source": [
    "Посмотрим в каком виде храниться картинка в памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjdN7d9-A7MX"
   },
   "outputs": [],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYbILY9JBZ1Q"
   },
   "source": [
    "Оказывается в формате [PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html)\n",
    "\n",
    "Что бы обучать модель нам придется преобразовать их в тензоры. \n",
    "Используем для этого transforms и Dataloder.\n",
    "\n",
    "Выведем размеры получившихся тензоров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qlvj98paBoFi"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "valset.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "val_dataloder = DataLoader(valset, batch_size=8, shuffle=False)\n",
    "\n",
    "for batch in train_dataloder:\n",
    "  images, class_nums = batch\n",
    "  print(len(batch))\n",
    "  print(\"Images: \",images.shape)\n",
    "  print(\"Class nums: \",class_nums.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_otzoVqWtxO"
   },
   "source": [
    "Разберемся с размерностями:\n",
    "на каждой итерации dataloader возвращает кортеж из двух элементов.\n",
    "Первый это изображения, второй метки классов.\n",
    "\n",
    "Количество элементов в каждом равно batch_size (8)\n",
    "\n",
    "Изображение:\n",
    "3 - C, каналы (В отличие от PIL и OpenCV они идут сначала)\n",
    "32 - H, высота\n",
    "32 - W, ширина \n",
    "\n",
    "Метки:\n",
    "числа от 0 до 9 по количеству классов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUj3aR1QFP8J"
   },
   "source": [
    "### Создадим модель - заглушку. \n",
    "\n",
    "Она не будет ничего предсказывать, только возвращать случайный номер класса.\n",
    "\n",
    "В методе fit данные просто запоминаются. Этот фрагмент кода можно будет использовать при выполнении практического задания.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocgpwAKCFL6H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FakeModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    self.train_data = torch.vstack((self.train_data,x)) if self.train_data != None else x\n",
    "    self.train_labels = torch.hstack((self.train_labels,y)) if self.train_labels != None else y\n",
    "   \n",
    "  def forward(self,x):\n",
    "    class_count = torch.unique(self.train_labels).shape[0]\n",
    "    class_num = torch.randint(low = 0, high = class_count-1, size = (x.shape[0],)) \n",
    "    return class_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viDoMFDvGio8"
   },
   "source": [
    "Запустим процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RxKNRzJODWw"
   },
   "outputs": [],
   "source": [
    "trainset.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "train_dataloder = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "\n",
    "model = FakeModel()\n",
    "\n",
    "for img_batch, labels_batch in train_dataloder:\n",
    "  model.fit(img_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sbzcpOIVsts"
   },
   "source": [
    "Проверим работу модели на нескольких изображениях из тестового набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vge98_CHQPTd"
   },
   "outputs": [],
   "source": [
    "img_batch, class_num_batch = next(iter(val_dataloder))\n",
    "predicted_cls_nums = model(img_batch)\n",
    "\n",
    "for i, predicted_cls_num in enumerate(predicted_cls_nums):\n",
    "  img = img_batch[i].permute(1,2,0).numpy()*255  \n",
    "  plt.subplot(1, len(predicted_cls_nums),i+1)\n",
    "  plt.imshow(img.astype(int))\n",
    "  plt.axis('off')\n",
    "  plt.title(labels[int(predicted_cls_num)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPDdmt5qWV39"
   },
   "source": [
    "Посчитаем точность "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5-zAE5PWYld"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = []\n",
    "for img_batch, labels_batch in val_dataloder:\n",
    "  predicted = model(img_batch)\n",
    "  batch_accuracy = accuracy_score(labels_batch, predicted)\n",
    "  accuracy.append(batch_accuracy)\n",
    "\n",
    "print(\"Accuracy\",torch.tensor(accuracy).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEjJz2M2ZVEo"
   },
   "source": [
    "Будем повышать точность. Заменим заглушку в методе predict реальным алгоритмом. Используем метод:\n",
    "\n",
    "K- Nearest Neighbor\n",
    "\n",
    "https://colab.research.google.com/drive/1_5tGxAoxrWulPmwK2Ht9BHGsS-EpxVo0?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPxZSlv43x_H"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### 1.5.2Метод ближайшего соседа\n",
    "\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/v1/knn.png\" >\n",
    "\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-25.jpg\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-26.jpg\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-27.jpg\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-28.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmK6yV3x2SKH"
   },
   "source": [
    "Метод K- ближайших соседей на CIFAR10. \n",
    "Если рассматрить его по шагам, то нужно альтернативное задание на практическую часть семинара. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBjcvp9OHqX0"
   },
   "source": [
    "# Практическая часть:\n",
    "\n",
    "https://colab.research.google.com/drive/1EPP7XSydB_k-g3h73He67k7mH9pPqUFS?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9pqYpu5lIc7"
   },
   "source": [
    "#Блок про локальную настройку\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
