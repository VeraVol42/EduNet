{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDG77F4f4zzx"
   },
   "source": [
    "## 1.5 Примеры задач решаемых при помощи методов машинного обучения\n",
    "\n",
    "\n",
    "Рассмотрим примеры решения задач классификации и линейной регресии на различных типах данных.\n",
    "\n",
    "\n",
    "Будем использовать библиотеки:\n",
    "* numpy\n",
    "* [skilearn](https://scikit-learn.org/stable/) - 'toy' датасеты, ML алгорытмы \n",
    "* [pandas](https://pandas.pydata.org/) - удобная работа с табличными данными\n",
    "\n",
    "познакомимся с инструментами:\n",
    "\n",
    "* **Pytorch** \n",
    "* **Tensorboard**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLlvxAHKxESh"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6y12nR9YpxU"
   },
   "source": [
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-16.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9wREYtJ6-6w"
   },
   "source": [
    "### 1.5.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMd2GsRfMmG4"
   },
   "outputs": [],
   "source": [
    "# Классификация вин \n",
    "# Используем библиотеку sklearn: https://scikit-learn.org/stable/ \n",
    "\n",
    "import sklearn \n",
    "from sklearn.datasets import load_wine\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "# Загрузка датасета\n",
    "data = load_wine(return_X_y = True) # Так же можно получить данные в Bunch(словарь) или pandas DataFrame\n",
    "\n",
    "features = data[0] # Массив 178x13 178 бутылок у каждой 13 признаков\n",
    "class_labels = data[1] # Массив из 178 элементов каждый элемент это число обозначающее класс к которому относиться данная бутылка : 0,1 2  \n",
    "print(\"Данные\",features.shape)\n",
    "print(\"Номер класса\",class_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tohStSfdt-NE"
   },
   "source": [
    "### 1.5.2 Визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3O4BBbqQJSNg"
   },
   "outputs": [],
   "source": [
    "# Подключим библиотеку для работы с табличнымии данными: https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "data_bunch = load_wine(return_X_y = False)\n",
    "print(data_bunch.keys())\n",
    "\"\"\"\n",
    "  Если параметр return_X_y == False\n",
    "  Данные в объекте Bunch: https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch \n",
    "  По сути это словарь.\n",
    "  Что бы отобразить данные в виде таблицы преобразуем их в формат pandas.DataFrame\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame(data_bunch.data, columns=data_bunch.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olpH1dK3Nc-p"
   },
   "source": [
    "Каждая строка в таблице может быть интерпретированна как вектор из 13 элементов. Можно интерпретировать такой вектор как координаты точки в 13 - мерном пространстве. Именно с таким представлением работают большинство алгоритмов машинного обучения. \n",
    "\n",
    "Визуализировать 13-мерное пространство не получиться :(. \n",
    "\n",
    "Но можно визуализировать проекцию данных в 3-х мерное пространство. Для этого воспользуемся инструментом projector из tensorboard\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80kpga5uVjw8"
   },
   "outputs": [],
   "source": [
    "# Вспомогательный метод для запуска Tensorboard в Colab\n",
    "\n",
    "# Fix: https://stackoverflow.com/questions/60730544/tensorboard-colab-tensorflow-api-v1-io-gfile-has-no-attribute-get-filesystem\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Запуск Tensorboard в Colab\n",
    "def reinit_tensorboard(clear_log = True):\n",
    "  # Лог-файлы читаются из этого каталога: \n",
    "  logs_base_dir = \"runs\"\n",
    "  if clear_log:\n",
    "    # Очистка логов\n",
    "    #!rm -rfv {logs_base_dir}/*\n",
    "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
    "    os.makedirs(logs_base_dir, exist_ok=True)\n",
    "  # Магия Colab\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtb8It_Rv3e1"
   },
   "source": [
    "После загрузки Tensorboard измените значение опции \"Color by\" на \"label 3 colors\" что бы объекты принадлежащие к разным классам отображались разными цветами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxCxSnsISXvy"
   },
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "np_f = numpy.array(features)\n",
    "writer.add_embedding(np_f, metadata=class_labels )\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjktILYlY99H"
   },
   "source": [
    "Рассказ про PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qM3rjfEObMd"
   },
   "source": [
    "Видно что объекты классов 1 и 2 линейно не разделимы в 2-х измерениях. По этой причине так популярен переход к пространствам большей размерности. \n",
    "\n",
    "Обратите внимание что данные центрированны около нуля - это результат нормализации которой они подверглись в Tensorboard.\n",
    "\n",
    "Нам тоже потребуется нормализовыть данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NWTf-ZPKXc"
   },
   "source": [
    "## 1.5.3 Нормализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udGzAucjZIUr"
   },
   "source": [
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/v2/min_max.png\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/v2/norm_distr.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4fJFRLGPQaC"
   },
   "outputs": [],
   "source": [
    "# Сделаем это средствами pytorch\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "\n",
    "\n",
    "# Отобразим значения двух параметров значения которых отличаются примерно на порядок\n",
    "f_names = data_bunch.feature_names\n",
    "for i, feature in enumerate(features):\n",
    "  writer.add_scalars(\"Raw_2_par\",{ \n",
    "      f_names[1]:feature[1], # malic_acid\n",
    "      f_names[3]:feature[3],  # alcalinity_of_ash\n",
    "     } ) \n",
    "\n",
    "# Добавим еще один значения которого отличается от второго на 2 порядка\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "  writer.add_scalars(\"Raw_3par\",{ \n",
    "                                     f_names[1]:feature[1], # malic_acid\n",
    "                                     f_names[3]:feature[3],  # alcalinity_of_ash\n",
    "                                     f_names[12]:feature[12] # proline \n",
    "                                     } ) \n",
    "\n",
    "# Добавим гистограмму для сырых данных.\n",
    "writer.add_histogram(\"1.Raw\" , features[:,3])\n",
    "writer.add_histogram(\"1.Raw\" , features[:,1])\n",
    "\n",
    "\n",
    "\n",
    "# Преобразовали данные к torch.Tensor \n",
    "tensor_f = torch.tensor(features)\n",
    "\n",
    "# Mini-Max  нормализация\n",
    "\n",
    "# torch.min и torch.max возвращают кортежи (values, indexes)\n",
    "# https://pytorch.org/docs/stable/generated/torch.min.html#torch.min\n",
    "\n",
    "min_values, _  = tensor_f.min(dim=1,keepdim=True)  # shape = (178,1)\n",
    "max_values, _  = tensor_f.max(dim=1,keepdim=True)  # shape = (178,1)\n",
    "\n",
    "# Вычитаем минимальное значение\n",
    "min_max_centered = tensor_f - min_values\n",
    "# Делим на среднее\n",
    "min_max_normalized =  min_max_centered / (max_values - min_values)\n",
    "\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,3])\n",
    "writer.add_histogram(\"2.Min_Max_Centered\" , min_max_centered[:,1])\n",
    "\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,3])\n",
    "writer.add_histogram(\"2.Min_Max_Normalized\" , min_max_normalized[:,1])\n",
    "\n",
    "# Стандартизация / Z-нормализация\n",
    "\n",
    "# Вычитаем среднее\n",
    "centered = tensor_f - tensor_f.mean(dim=0)\n",
    "# Разделим на стандартное отклонение\n",
    "normalized = centered / tensor_f.std(dim=0)\n",
    "\n",
    "# Добавим гистограмму для стандартизированных данных в Tensorboard\n",
    "writer.add_histogram(\"3.Centered\" , centered[:,3])\n",
    "writer.add_histogram(\"3.Centered\" , centered[:,1])\n",
    "\n",
    "writer.add_histogram(\"3.Normalized\" , normalized[:,3])\n",
    "writer.add_histogram(\"3.Normalized\" , normalized[:,1])\n",
    "\n",
    "\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , features[:,1])\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , min_max_normalized[:,1])\n",
    "writer.add_histogram(\"4.Mix: raw, MM, Z\" , normalized[:,1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9Y5GHEqnLp9"
   },
   "source": [
    "## 1. После загрузки Tensorboard выберите пункт меню \"SCALARS\"\n",
    "затем 'Horizontal Axis' = Relative\n",
    "\n",
    "Значения в разных масштабах - несравнимы между собой\n",
    "\n",
    "## 2. выберите пункт меню \"HISTOGRAMS\"\n",
    "затем Offset time axis = WALL или RELATIVE\n",
    "\n",
    "Наглядное приемущество Стандартизации перед max-min нормализацией\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj3nWSjhmtnJ"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf-95rOeHYat"
   },
   "source": [
    "### 1.5.4 Обучение\n",
    "\n",
    "Базовая документация\n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "Пример использования SVM классификатора\n",
    "https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqs6K8JZwh1u"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, class_labels, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"X_train\",X_train.shape)\n",
    "print(\"X_test\",X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-dQz4BpVrKK"
   },
   "source": [
    "##№ 1.5.5 Обучим модель и посчитаем точность (Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irm2wG821UlR"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# Создаем модель\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "# Обучаем модель на части данных\n",
    "lin_clf.fit(X_train, y_train)\n",
    "\n",
    "# Получаем предсказания\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "print(\"y_pred\",y_pred.shape)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3-xyVqLH_qr"
   },
   "source": [
    "#Аналогичным образом можно работать с различными типами данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i9W1LaBWAZS"
   },
   "source": [
    "**Загрузка даннных.**\n",
    "\n",
    "В Pytorch есть три библиотеки для работы с разными типами данных:\n",
    "\n",
    "[torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "[torchaudio](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html)\n",
    "\n",
    "\n",
    "Для загрузки данных  используются классы [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) и [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). \n",
    "\n",
    "Они предоставляют единый интерфейс для доступа к данным различных типов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgYqyAgm2uF4"
   },
   "source": [
    "# Пример загрузки аудио средствами Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOlzSR45IaLj"
   },
   "source": [
    "Установим библиотеку torch.audio она не входит в список пакетов доступных в colab по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJUjZX_yboQk"
   },
   "outputs": [],
   "source": [
    "!pip install torchaudio==0.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDI5LRLiIsWI"
   },
   "source": [
    "##Загрузим датасет\n",
    "\n",
    "Speech Commands:  A Dataset for Limited-Vocabulary SpeechRecognition\n",
    "\n",
    "https://arxiv.org/pdf/1804.03209.pdf\n",
    "\n",
    "https://pytorch.org/audio/stable/datasets.html#speechcommands\n",
    "\n",
    "Данные будут распакованны в папку sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raahLh_R2k0p"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "speech_commands_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"sample_data\",download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oS7IVuiGOP_"
   },
   "source": [
    "\n",
    "Объект speech_commands_dataset - это экземпляр класса который является наследником  [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html) это означает что в нем реализованы методы \n",
    "* __getitem__ \n",
    "* __len__\n",
    "\n",
    "Благодаря этому, мы можем узнать количество элементов или получить произвольный элемент данных обращаясь к объекту класса Dataset  так же как к обычному списку в python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktqQtSLtIUIu"
   },
   "outputs": [],
   "source": [
    "print(\"Количество элементов {} \".format(len(speech_commands_dataset)))\n",
    "print(\"Первый элемент\",speech_commands_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACQxVzNiH00E"
   },
   "source": [
    "## Что представляет из себя элемент аудио - данных?\n",
    "Обратимся к документации: https://pytorch.org/audio/stable/datasets.html#speechcommands\n",
    "\n",
    "... returns:\n",
    "\n",
    "    (waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "utterance_number - номер повтора. Больше нуля если один и тот же человек проговаривает одну и ту же фразу несколько раз. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0tH4UF8KKiC"
   },
   "outputs": [],
   "source": [
    "waveform, sample_rate, label, speaker_id, utterance_number = speech_commands_dataset[0]\n",
    "print(\"Waveform: {}\\nSample rate: {}\\nLabel: {} \\nSpeaker_id: {} \\nutterance_number: {}\".format(waveform.shape, sample_rate, label,speaker_id,utterance_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1meIJy9PNo7"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjHSl83yNbxV"
   },
   "source": [
    "\n",
    "Размеры тензора waveform:\n",
    "    \n",
    "    [1, 16000] \n",
    "\n",
    "1- количество каналов, 16000 количество измерений в секунду\n",
    "\n",
    "Если частота дискретизации(sample_rate) равна 16000 то этот фрагмент занимает ровно 1 секунду \n",
    "\n",
    "Визуализируем их:\n",
    "x - время\n",
    "y - давление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FjgzXIOQNk27"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(type(waveform))\n",
    "plt.figure()\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.plot(waveform.t().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYcb2s93N9gT"
   },
   "source": [
    "# Озвучим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpKCYA0-OGSL"
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv2IyIdiVdTZ"
   },
   "source": [
    "## Итерация по датасету.\n",
    "\n",
    "Для начала запустим простую проверку: убедимся что все записи одинаковой длины.\n",
    "\n",
    "### Почему это важно\n",
    "\n",
    "* list\n",
    "* numpy - массив\n",
    "* torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AstmNrPNWLvv"
   },
   "source": [
    "Проверим что все записи имеют одинаковую длину. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsCRUVh1Wjrv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def_length = 16000\n",
    "for i, sample in enumerate(speech_commands_dataset):\n",
    "  waveform, sample_rate, label, speaker_id, utterance_number = sample\n",
    "  if def_length != waveform.shape[1]: # [1, 16000]\n",
    "    print(i)\n",
    "    print(\"Waveform: {}\\nSample rate: {}\\nLabel: {} \\nSpeaker_id: {} \\nutterance_number: {}\".format(waveform.shape, sample_rate, label,speaker_id,utterance_number))\n",
    "    break\n",
    "  if not i% 10000 and i > 0 :\n",
    "    print(f\"Processed {i} objects\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yed0_9fTZKJT"
   },
   "source": [
    "Если не все элементы будут иметь различную длину мы не сможем их сравнивать. И даже технически поместить в один массив. Необходомо их выровнять. Так как многие записи начинаются и заканчиваются тишиной, то просто дополним их нулями.\n",
    "Для этого применим концепцию трансформаций (transform) которая широко применяется в Pytorch и встраивается во многие датасеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfekd5aSbd9j"
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "class PadWaveform(torch.nn.Module):\n",
    "  def __init__(self, desired_size = 16000):\n",
    "    self.desired_size = desired_size\n",
    "    super().__init__()\n",
    "\n",
    "  # in nn.Module forward method called inside __call__ method\n",
    "\n",
    "  def forward(self, waveform):\n",
    "    if waveform.shape[1] < self.desired_size:\n",
    "      diff = self.desired_size - waveform.shape[1]\n",
    "      pad_left = diff // 2\n",
    "      pad_right = diff - pad_left\n",
    "      return torch.nn.functional.pad(waveform,[pad_left, pad_right])\n",
    "    else:\n",
    "      return waveform\n",
    "\n",
    "class customSpeechCommandsDataset(torchaudio.datasets.SPEECHCOMMANDS):\n",
    "  def __init__(self,transform,root = \"sample_data\"):\n",
    "    self.transform = transform\n",
    "    super().__init__(root)\n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self,n):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    transformed_waveform = self.transform(waveform)\n",
    "    return (transformed_waveform, sample_rate, label, speaker_id, utterance_number)\n",
    "\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform = torch.nn.Sequential(PadWaveform(16000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usKlStbZgC7K"
   },
   "source": [
    "Теперь можно добавлять дополнительные трансформации. Например уменьшить частоту дискретизации (sample_rate) что бы данные занимали меньше места.\n",
    "\n",
    "Для этого в модуле:\n",
    "[torchaudio.transforms](https://pytorch.org/audio/stable/transforms.html#resample)  уже есть готовая трансформация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCXvbnpDgx3l"
   },
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDataset(transform = torch.nn.Sequential(\n",
    "    Resample(16000,8000),\n",
    "    PadWaveform(8000))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Pf6OugkhzVy"
   },
   "source": [
    "### Визуализируем данные\n",
    "\n",
    "Датасет в архиве занимает > 2Gb и это далеко не предел. Поэтому работать с ним будем по частям. \n",
    "\n",
    "Для этой задачи в pytorch используется класс Dataloader. Одной из его функций является пакетная(batch) загрузка данных. Особенно она будет полезна при обучении. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sI9S3rsiKj2"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(speech_commands_dataset, batch_size=512, shuffle=True)\n",
    "\n",
    "writer = SummaryWriter(comment = \"commands\")\n",
    "\n",
    "for i, batch in enumerate(data_loader):\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "  print(waveforms.shape)\n",
    "  print(labels)\n",
    "  # Данные преобразовались в тензоры\n",
    "  # Убираем 1-е измерение оставшееся от канала\n",
    "  writer.add_embedding(torch.squeeze(waveforms), metadata=labels )\n",
    "  break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dPYh7B_lr3G"
   },
   "source": [
    "##Запустим Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q_NKnewlpen"
   },
   "outputs": [],
   "source": [
    "reinit_tensorboard(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYVESERLqLRp"
   },
   "source": [
    "### Надо ли нормализовать эти данные?\n",
    "\n",
    "Загрузим значения 2-х произвольных признаков в Tensorboard b проверим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90ZuZCwRn6ta"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment = \"commands\")\n",
    "for i, batch in enumerate(data_loader):\n",
    "  waveforms, sample_rates, labels, speaker_ids, utterance_numbers = batch\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,100])\n",
    "  writer.add_histogram(\"waves\" ,torch.squeeze(waveforms)[:,200])\n",
    "  break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ci3HGTqei5"
   },
   "source": [
    "Как видно из гистограммы, данные уже центрированны вкруг нуля и имеют один масшаб. Отчасти это связанно с тем что что они имеют одну и ту же природу, отчасти с форматом хранения звука. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IB3k4rvZyYpC"
   },
   "source": [
    "### Обучение\n",
    "\n",
    "Для обучения потребуются метки. Попутно избавимся от лишнего. Создадим очередную трансформацию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4WGKr9gyq-c"
   },
   "outputs": [],
   "source": [
    "class ClassName2Num(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, waveform):\n",
    "    if waveform.shape[1] < self.desired_size:\n",
    "      diff = self.desired_size - waveform.shape[1]\n",
    "      pad_left = diff // 2\n",
    "      pad_right = diff - pad_left\n",
    "      return torch.nn.functional.pad(waveform,[pad_left, pad_right])\n",
    "    else:\n",
    "      return waveform\n",
    "\n",
    "class customSpeechCommandsDatasetFinal(customSpeechCommandsDataset):\n",
    "  def __init__(self,transform = torch.nn.Sequential(),root = \"sample_data\"):\n",
    "    super().__init__(transform,root)\n",
    "    self.labels = self.get_labels()\n",
    "\n",
    "  def get_labels(self):\n",
    "    labels = set()\n",
    "    for i in range(len(self)):\n",
    "      item = super(customSpeechCommandsDataset,self).__getitem__(i)\n",
    "      labels.add(item[2])\n",
    "    return sorted(list(labels)) \n",
    "\n",
    "  # Override \n",
    "  def __getitem__(self,n):\n",
    "    waveform, sample_rate, label, speaker_id, utterance_number = super().__getitem__(n)\n",
    "    return (waveform[0],self.labels.index(label))\n",
    "\n",
    "speech_commands_dataset = customSpeechCommandsDatasetFinal(transform = torch.nn.Sequential(\n",
    "    Resample(16000,8000),\n",
    "    PadWaveform(8000))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zB2PGDa965J5"
   },
   "outputs": [],
   "source": [
    "print(\"Classes\",speech_commands_dataset.labels)\n",
    "print(\"Classes num\",len(speech_commands_dataset.labels))\n",
    "\n",
    "wave, cls_num = speech_commands_dataset[0]\n",
    "print(wave.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_t-wlLr9yHU"
   },
   "source": [
    "Разделим данные на обучающую и валидационную выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRpKWF6Z97XT"
   },
   "outputs": [],
   "source": [
    "total_len = len(speech_commands_dataset )\n",
    "print(\"Total length\",total_len)\n",
    "val_len = int(total_len*0.1)\n",
    "train_set, val_set = torch.utils.data.random_split(speech_commands_dataset, [total_len - val_len, val_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHPh5xGg1QII"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def validate(model):\n",
    "  data_loader = torch.utils.data.DataLoader(val_set, batch_size=1000, shuffle=False)\n",
    "  accuracy = []\n",
    "  for batch in data_loader:\n",
    "    waveforms, class_nums  = batch \n",
    "    y_pred = model.predict(waveforms)\n",
    "    accuracy.append(metrics.accuracy_score(class_nums, y_pred))\n",
    "  print(\"Accuracy:\",numpy.array(accuracy).mean())\n",
    "\n",
    "model = SGDClassifier(loss='log')  \n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=20000, shuffle=True)\n",
    "for batch in data_loader:\n",
    "  waveforms, class_nums  = batch\n",
    "  model.partial_fit(waveforms, class_nums,range(35))\n",
    "  validate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VH071PjLHTJp"
   },
   "source": [
    "Точность низкая. Для работы с этими данными нужна глубокая модель.\n",
    "С ее помощью можно получить точность >85%:\n",
    "\n",
    "[Speech Command Recognition with torchaudio](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/d87597d0062580c9ec699193e951e3f4/speech_command_recognition_with_torchaudio.ipynb#scrollTo=tl9K6deU4S10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aDSMa9v5PfK"
   },
   "source": [
    "## Место для рассказа про то чем строка в таблице принципиально отличается от аудиозаписи.\n",
    "\n",
    "\n",
    "....\n",
    "\n",
    "Вероятно тут стоит добавить несколько картинок.\n",
    "\n",
    "....\n",
    "\n",
    "\n",
    "* 1D - Таблица (столбцы не упорядоченны)\n",
    "* 2D - Аудио (данные упорядоченны по времени)\n",
    "* 3D - Монохромные изображения\n",
    "* 4D - Цветные изображения, монохромные 3-х мерные изображения (МРТ)\n",
    "* 5D - Видео, Воксельные изображения\n",
    "* 6D - 3-мерное видео "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W46TbNCa6VjW"
   },
   "source": [
    "#Работа с изображениями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMwAHqiA7jc1"
   },
   "source": [
    "Загрузим датасет CIFAR-10. Он состоит из 60000 цветных изображений размером 32x32. На картинках объекты 10 классов.\n",
    "\n",
    "\n",
    " В отличие от torchaudio пакет torchvision при помощи которого загружается датасет входит в число предустановленных в colab.\n",
    "\n",
    "Датасеты из torcvision изначально поддерживают механизм transforms - нам не придется добавлять их вручную.\n",
    "\n",
    "Равно как и разбивку на тестовое и проверочные подмножества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-h-9uOw_W1-"
   },
   "outputs": [],
   "source": [
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainset = datasets.CIFAR10(\"content\", train=True,  download=True)\n",
    "valset = datasets.CIFAR10(\"content\", train = False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cA_6ApRo_39h"
   },
   "source": [
    "Выведем несколько картинок вместе с метками. Tensorboard имееи метод для вывода кртинок:\n",
    "[torchvision.utils.make_grid](https://pytorch.org/docs/stable/torchvision/utils.html)\n",
    "\n",
    "Однако он не поддерживает метки.\n",
    "\n",
    "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjcxcStpNDtAhWllYsKHa7XDLoQFjAAegQIBBAC&url=https%3A%2F%2Fdiscuss.pytorch.org%2Ft%2Fadd-label-captions-to-make-grid%2F42863&usg=AOvVaw19bkv0_Q8VQxD7WBZ3pFR_\n",
    "\n",
    "Поэтому воспользуемся matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhRzzRB6_8xV"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# Загрузим названия классов. Исключительно для наглядности, для обучения модели они не нужны.\n",
    "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\n",
    "  cifar_meta = pickle.load(infile)\n",
    "labels = cifar_meta['label_names']\n",
    "\n",
    "for j in range(10):\n",
    "  image, class_num = trainset[j]\n",
    "  plt.subplot(1, 10 ,j+1)\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')  \n",
    "  plt.title(labels[class_num])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnIGtMngAzy_"
   },
   "source": [
    "Посмотрим в каком виде храниться картинка в памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjdN7d9-A7MX"
   },
   "outputs": [],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYbILY9JBZ1Q"
   },
   "source": [
    "Оказывается в формате [PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html)\n",
    "\n",
    "Что бы обучать модель нам придется преобразовать их в тензоры. \n",
    "Используем для этого transforms и Dataloder.\n",
    "\n",
    "Выведем размеры получившихся тензоров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qlvj98paBoFi"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "valset.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "val_dataloder = DataLoader(valset, batch_size=8, shuffle=False)\n",
    "\n",
    "for batch in train_dataloder:\n",
    "  images, class_nums = batch\n",
    "  print(len(batch))\n",
    "  print(\"Images: \",images.shape)\n",
    "  print(\"Class nums: \",class_nums.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_otzoVqWtxO"
   },
   "source": [
    "Разберемся с размерностями:\n",
    "на каждой итерации dataloader возвращает кортеж из двух элементов.\n",
    "Первый это изображения, второй метки классов.\n",
    "\n",
    "Количество элементов в каждом равно batch_size (8)\n",
    "\n",
    "Изображение:\n",
    "3 - C, каналы (В отличие от PIL и OpenCV они идут сначала)\n",
    "32 - H, высота\n",
    "32 - W, ширина \n",
    "\n",
    "Метки:\n",
    "числа от 0 до 9 по количеству классов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUj3aR1QFP8J"
   },
   "source": [
    "### Создадим модель - заглушку. \n",
    "\n",
    "Она не будет ничего предсказывать, только возвращать случайный номер класса.\n",
    "\n",
    "В методе fit данные просто запоминаются. Этот фрагмент кода можно будет использовать при выполнении практического задания.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocgpwAKCFL6H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class FakeModel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    self.train_data = torch.vstack((self.train_data,x)) if self.train_data != None else x\n",
    "    self.train_labels = torch.hstack((self.train_labels,y)) if self.train_labels != None else y\n",
    "   \n",
    "  def forward(self,x):\n",
    "    class_count = torch.unique(self.train_labels).shape[0]\n",
    "    class_num = torch.randint(low = 0, high = class_count-1, size = (x.shape[0],)) \n",
    "    return class_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viDoMFDvGio8"
   },
   "source": [
    "Запустим процесс обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RxKNRzJODWw"
   },
   "outputs": [],
   "source": [
    "trainset.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "train_dataloder = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "\n",
    "model = FakeModel()\n",
    "\n",
    "for img_batch, labels_batch in train_dataloder:\n",
    "  model.fit(img_batch, labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sbzcpOIVsts"
   },
   "source": [
    "Проверим работу модели на нескольких изображениях из тестового набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vge98_CHQPTd"
   },
   "outputs": [],
   "source": [
    "img_batch, class_num_batch = next(iter(val_dataloder))\n",
    "predicted_cls_nums = model(img_batch)\n",
    "\n",
    "for i, predicted_cls_num in enumerate(predicted_cls_nums):\n",
    "  img = img_batch[i].permute(1,2,0).numpy()*255  \n",
    "  plt.subplot(1, len(predicted_cls_nums),i+1)\n",
    "  plt.imshow(img.astype(int))\n",
    "  plt.axis('off')\n",
    "  plt.title(labels[int(predicted_cls_num)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPDdmt5qWV39"
   },
   "source": [
    "Посчитаем точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5-zAE5PWYld"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = []\n",
    "for img_batch, labels_batch in val_dataloder:\n",
    "  predicted = model(img_batch)\n",
    "  batch_accuracy = accuracy_score(labels_batch, predicted)\n",
    "  accuracy.append(batch_accuracy)\n",
    "\n",
    "print(\"Accuracy\",torch.tensor(accuracy).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEjJz2M2ZVEo"
   },
   "source": [
    "Будем повышать точность. Заменим заглушку в методе predict реальным алгоритмом. Используем метод:\n",
    "\n",
    "K- Nearest Neighbor\n",
    "\n",
    "https://colab.research.google.com/drive/1_5tGxAoxrWulPmwK2Ht9BHGsS-EpxVo0?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPxZSlv43x_H"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### 1.5.2Метод ближайшего соседа\n",
    "\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/v1/knn.png\" >\n",
    "\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-25.jpg\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-26.jpg\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-27.jpg\" >\n",
    "<img src =\"https://edunet.kea.su/EduNet/source/L1_Intro/img/intro-28.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmK6yV3x2SKH"
   },
   "source": [
    "Метод K- ближайших соседей на CIFAR10. \n",
    "Если рассматрить его по шагам, то нужно альтернативное задание на практическую часть семинара. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBjcvp9OHqX0"
   },
   "source": [
    "# Практическая часть:\n",
    "\n",
    "https://colab.research.google.com/drive/1EPP7XSydB_k-g3h73He67k7mH9pPqUFS?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9pqYpu5lIc7"
   },
   "source": [
    "#Блок про локальную настройку\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "L01_Samples.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
