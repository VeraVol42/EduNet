{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BPcyQRmXq8I"
   },
   "source": [
    "# 1.1 Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRJ-JLXkb2PN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHiB-TsSVCcV"
   },
   "source": [
    "\n",
    "### 1.1.1 Место глубокого обучения и нейронных сетей в ИИ\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro1.png\" >\n",
    "\n",
    "**Искусственный интеллект (AI/ИИ)**  ~= область ИТ/Computer science связанная с моделированием интеллектуальных или творческих видов человеческой деятельности.\n",
    "\n",
    "**Машинное обучение(ML)** - подраздел ИИ связанный с обучением на данных, он не единственный. Например базы знаний или многоагентные системы также относят к разделам ИИ. \n",
    "\n",
    "**Глубокое обучение (Deep Learning, DL)** ~= Многослойная нейросеть (MLP = multi layer perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6uYWy01di2p"
   },
   "source": [
    "### 1.1.2 Области применения DL\n",
    "\n",
    "<img src =\"http://edunet.kea.su/EduNet/source/L1_Intro/img/mp/Intro2.jpg\" >\n",
    "\n",
    "В последнее время, технологии DL успешно применяются для решения задач в области компьютерного зрения (Computer Vision, CV), oбработки текстов на естественных языках (NLP)(извлечение смысла, машинный перевод), распознавание речи.\n",
    "\n",
    "В данном курсе мы подробно рассмотрим технологии DL применяющиеся в этих областях.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TiPYPVaeNiZ"
   },
   "source": [
    "### 1.1.3 Связь DL с наукой\n",
    "\n",
    "<img src =\"http://edunet.kea.su/Intro3.png\" >\n",
    "\n",
    "Помимо прикладных задач существуют еще и научные исследования, результаты которых до известной степени непредсказуемы. Несльзя исключить что он появятся в областях где технологии DL до сих пор активно не использовались.\n",
    "\n",
    " Поддержка такого рода исследований есть основная задача курса нашего курса.\n",
    "\n",
    "\n",
    " Вариант2:\n",
    "\n",
    " Мы видим что NN уже нашли применение в множестве массовых(типовых) задач которые нас окружают.\n",
    "\n",
    "Однако каждая научная работа индивидуальна, в этом состоит сложность: только автор понимает как обрабатываются данные в его предметной области и как следует оценить результат.\n",
    "\n",
    "Но не всегда ученые особенно из естественных или гуманитарных областей готовы самостоятельно применить ML к объекту своих исследований.\n",
    "Поэтому мы здесь ...\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzTmT5m5e-hN"
   },
   "source": [
    "# 1.2 История глубокого обучения\n",
    "\n",
    "* 1957 Перцептрон,  Фрэнк Розенблатт\n",
    "* 1959 Hubel & Wiesel\n",
    "* 1959 \"The XOR affair\" Marvin Minsky, Seymour Papert\n",
    "* 1975 Cognitron: A self-organizing multilayered neural network K.Fukushima, \n",
    "* 1986 Backpropagation Rumelhart, Hinton & Williams ( 1974 А. И. Галушкин)\n",
    "* 1989 LeNet.  LeCun,  et al\n",
    "* 2012 AlexNet Krizhevsky et al\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XorAF-FgpGF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V-s9vYSW21U"
   },
   "source": [
    "### 1.2.2 Победа нейросети AlexNet на соревновании ImageNet в 2012\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro4.png\" >\n",
    "\n",
    "### 1.2.3 ImageNet: Large Scale Visual Recognition Challenge (ILSVRC)\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro5.png\" >\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUEkABb2lllH"
   },
   "source": [
    "## 1.3 Области применения DL в настоящее время\n",
    "\n",
    "### 1.3.1  Робототехника\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro6.png\" >\n",
    "Беспилотные автомобили Self-Driving Car и дроны\n",
    "Промышленные и бытовые роботы.\n",
    "\n",
    "### 1.3.2 Безопасность\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro7.png\" >\n",
    "\n",
    "\n",
    "Видеоаналитика, контроль доступа, распознавние лиц, номеров.\n",
    "\n",
    "\n",
    "### 1.3.3 Интернет и дополненная реальность\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro8.png\" >\n",
    "\n",
    "Поиск в том числе семантический. Анализ контента, в том числе визуального. Машинный перевод. Распознавание речи.\n",
    "\n",
    "\n",
    "\n",
    "### 1.3.4 Медицина\n",
    "\n",
    "- добавить примеров\n",
    "\n",
    "### 1.3.5 Применение DL в научных исследованиях\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro9.png\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro10.png\" >\n",
    "\n",
    "\n",
    "\n",
    "### 1.3.7 Причины успехов технологий на основе DL\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro11.png\" >\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXDX8IY8xw_3"
   },
   "source": [
    "## 1.4 Задачи решаемые при помощи машинного обучения\n",
    "\n",
    "### 1.4.1 Извлечение закономерностей\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro13.png\" >\n",
    "\n",
    "Ученый многократно наблюдает за ходом процесса и делает обобщения.\n",
    "\n",
    "Результатом такой работы является модель описывающая некоторые процессы реального мира.\n",
    "\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro14.png\" >\n",
    "\n",
    "ML - технология которая позволяет выявлять закономерности в данных и обобщать их. \n",
    "\n",
    "Результатом обучения такой модели является набор весов. \n",
    "\n",
    "По сути это набор коэффициентов для некоторого математического выражения.\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro15.png\" >\n",
    "\n",
    "Законы Ньютоны не сформулированны для яблок.\n",
    "Для описания закономерностей в науке используются абстракции:  сила, масса ускорение которыми описываются реальные объекты.\n",
    "\n",
    "Данные для ML моделей тоже должны быть подготовлены. Типичная форма такой абстракции вектор чисел.\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro16.png\" >\n",
    "\n",
    "Второй частью процесса обучения является оценка результата. \n",
    "\n",
    "Полученный результат сравнивают с эталонным  и если разница велика - корректируют модель.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEk8ruzC1BRb"
   },
   "source": [
    "## Пример\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro17.png\" >\n",
    "\n",
    "Нужно посчитать количество шагов используя показания акселерометра встроенного в шагомер. \n",
    "\n",
    "#### Вариант №1\n",
    "\n",
    "Написать программу ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-GdKRVh1fAp"
   },
   "outputs": [],
   "source": [
    "if x[i] > x[i - k] and y[i] > y[i - k] and ...\n",
    "  ....\n",
    "else:\n",
    "  ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDxLDZPo1rjl"
   },
   "source": [
    "\n",
    "Вариант №2\n",
    "\n",
    "Обучить модель\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro18.png\" >\n",
    "\n",
    "При этом можно не занать ничего о природе сигналов. Важно лиш собрать достаточное количество данных и разметить их.\n",
    "Разметка в данном случае будет заключаться в с боре информации о том сколько фактически шагов сделал человек.\n",
    "\n",
    "## 1.4.3 Базовые задачи\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro19.png\" >\n",
    "\n",
    "## 1.4.3 Виды данных\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/Intro20.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DukPy4wh1gBW"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o346mPzulsAV"
   },
   "source": [
    "\n",
    "#1.4.4 Оценка результата\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-17.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-18.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-19.jpg\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/accuracy.png\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-21.jpg\" >\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDG77F4f4zzx"
   },
   "source": [
    "## 1.5 Примеры задач решаемых при помощи методов машинного обучения\n",
    "\n",
    "\n",
    "Рассмотрим примеры решения задач классификации и линейной регресии на различных типах данных.\n",
    "\n",
    "А так же познакомимся с инструментами:\n",
    "**Pytorch** и **Tensorboard**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLlvxAHKxESh"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9wREYtJ6-6w"
   },
   "source": [
    "### 1.5.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1371,
     "status": "ok",
     "timestamp": 1606970743178,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "TMd2GsRfMmG4",
    "outputId": "6200a317-464a-4415-ebbd-28ae8ccbb80e"
   },
   "outputs": [],
   "source": [
    "# Классификация вин \n",
    "# Используем библиотеку sklearn: https://scikit-learn.org/stable/ \n",
    "\n",
    "import sklearn \n",
    "from sklearn.datasets import load_wine\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "# Загрузка датасета\n",
    "data = load_wine(return_X_y = True) # Так же можно получить данные в Bunch(словарь) или pandas DataFrame\n",
    "\n",
    "features = data[0] # Массив 178x13 178 бутылок у каждой 13 признаков\n",
    "class_labels = data[1] # Массив из 178 элементов каждый элемент это число обозначающее класс к которому относиться данная бутылка : 0,1 2  \n",
    "print(\"Данные\",features.shape)\n",
    "print(\"Номер класса\",class_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tohStSfdt-NE"
   },
   "source": [
    "### 1.5.2 Визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1606970890376,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "3O4BBbqQJSNg",
    "outputId": "59d064b9-fde2-4844-c32d-c7576596ae50"
   },
   "outputs": [],
   "source": [
    "# Подключим библиотеку для работы с табличнымии данными: https://pandas.pydata.org/\n",
    "import pandas as pd \n",
    "\n",
    "data_bunch = load_wine(return_X_y = False)\n",
    "print(data_bunch.keys())\n",
    "\"\"\"\n",
    "  Если параметр return_X_y == False\n",
    "  Данные в объекте Bunch: https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch \n",
    "  По сути это словарь.\n",
    "  Что бы отобразить данные в виде таблицы преобразуем их в формат pandas.DataFrame\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame(data_bunch.data, columns=data_bunch.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olpH1dK3Nc-p"
   },
   "source": [
    "Каждая строка в таблице может быть интерпретированна как вектор из 13 элементов. Можно интерпретировать такой вектор как координаты точки в 13 - мерном пространстве. Именно с таким представлением работают большинство алгоритмов машинного обучения. \n",
    "\n",
    "Визуализировать 13-мерное пространство не получиться :(. Но можно визуализировать проекцию данных в 3-х мерное пространство. Для этого воспользуемся инструментом projector из tensorboard\n",
    "\n",
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1934,
     "status": "ok",
     "timestamp": 1606970970922,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "80kpga5uVjw8"
   },
   "outputs": [],
   "source": [
    "# Вспомогательный метод для запуска Tensorboard в Colab\n",
    "\n",
    "# Fix https://stackoverflow.com/questions/60730544/tensorboard-colab-tensorflow-api-v1-io-gfile-has-no-attribute-get-filesystem\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "import os\n",
    "# Запуск Tensorboard в Colab\n",
    "def reinit_tensorboard(clear_log = True):\n",
    "  # Лог-файлы читаются из этого каталога: \n",
    "  logs_base_dir = \"runs\"\n",
    "  if clear_log:\n",
    "    # Очистка логов\n",
    "    !rm -rfv {logs_base_dir}/*\n",
    "    os.makedirs(logs_base_dir, exist_ok=True)\n",
    "  # Магия Colab\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtb8It_Rv3e1"
   },
   "source": [
    "После загрузки Tensorboard измените значение опции \"Color by\" на \"label 3 colors\" что бы объекты принадлежащие к разным классам отображались разными цветами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "np_f = numpy.array(features)\n",
    "writer.add_embedding(np_f, metadata=class_labels )\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qM3rjfEObMd"
   },
   "source": [
    "Видно что объекты классов 1 и 2 линейно не разделимы в 2-х измерениях. По этой причине так популярен переход к пространствам большей размерности. \n",
    "\n",
    "Обратите внимание что данные центрированны около нуля - это результат нормализации которой они подверглись в Tensorboard.\n",
    "\n",
    "Нам тоже потребуется нормализовыть данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6NWTf-ZPKXc"
   },
   "source": [
    "## 1.5.3 Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем это средствами pytorch\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "tensor_f = torch.tensor(features)\n",
    "centered = tensor_f - tensor_f.mean(dim=0)\n",
    "print(tensor_f.std(dim=0))\n",
    "print(centered[0])\n",
    "normalized = centered / tensor_f.std(dim=0)\n",
    "print(normalized[0])\n",
    "\n",
    "reinit_tensorboard()\n",
    "writer = SummaryWriter(comment = \"wine\")\n",
    "#writer.add_embedding(normalized, metadata=class_labels )\n",
    "writer.add_histogram(data_bunch.feature_names[0] + \"_raw\", tensor_f[:,0], global_step=None, bins='tensorflow', walltime=None, max_bins=None)\n",
    "writer.add_histogram(data_bunch.feature_names[0] + \"_normalized\", normalized[:,0], global_step=None, bins='tensorflow', walltime=None, max_bins=None)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf-95rOeHYat"
   },
   "source": [
    "### 1.5.4 Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm7-6_CbHfEa"
   },
   "source": [
    "### 1.5.5  Посчитать Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3-xyVqLH_qr"
   },
   "source": [
    "#То же самое для аудио- данных + Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i9W1LaBWAZS"
   },
   "source": [
    "**Загрузка даннных.**\n",
    "\n",
    "В Pytorch есть три библиотеки для работы с разными типами данных:\n",
    "\n",
    "[torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "[torchaudio](https://pytorch.org/audio/stable/datasets.html)\n",
    "\n",
    "[torchtext](https://pytorch.org/text/stable/index.html)\n",
    "\n",
    "\n",
    "Для загрузки данных  используются классы [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) и [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). \n",
    "\n",
    "Они предоставляют единый интерфейс для доступа к данным различных типов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJUjZX_yboQk"
   },
   "outputs": [],
   "source": [
    "!pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1606293011053,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "F6I2XhCjV7dr",
    "outputId": "787a062f-62ce-4c41-81ae-cb9061433e3c"
   },
   "outputs": [],
   "source": [
    "# Пример загрузки аудио.\n",
    "\n",
    "# Speech Commands:  A Dataset for Limited-Vocabulary SpeechRecognition\n",
    "# https://arxiv.org/pdf/1804.03209.pdf\n",
    "# https://pytorch.org/audio/stable/datasets.html#speechcommands\n",
    "\n",
    "import torchaudio\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#speech_commands_dataset = torchaudio.datasets.SPEECHCOMMANDS(\"sample_data\",download = True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(speech_commands_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for sample in data_loader:\n",
    "  # Dataloader must return a batch but somtime single item can be returned :(  \n",
    "  waveform,  sample_rate, labels = sample[:3]\n",
    "  print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform.shape, sample_rate, labels))\n",
    "\n",
    "  plt.figure()\n",
    "  plt.title(f\"Label: {labels[0]}\")\n",
    "  plt.plot(waveform[0].t().numpy())\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXJCwh7f2hOT"
   },
   "outputs": [],
   "source": [
    "Включить примеры рассчета метрик!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmK6yV3x2SKH"
   },
   "source": [
    "Метод K- ближайших соседей на CIFAR10. \n",
    "Если рассматрить его по шагам, то нужно альтернативное задание на практическую часть семинара. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPxZSlv43x_H"
   },
   "source": [
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-16.jpg\" >\n",
    "\n",
    "### 1.5.2Метод ближайшего соседа\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro_v1/knn.png\" >\n",
    "\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-25.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-26.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-27.jpg\" >\n",
    "<img src =\"http://fmb.images.gan4x4.ru/msu/intro/intro-28.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBjcvp9OHqX0"
   },
   "source": [
    "# Практическая часть:\n",
    "\n",
    "https://colab.research.google.com/drive/1EPP7XSydB_k-g3h73He67k7mH9pPqUFS?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnYXdaJb09Sg"
   },
   "outputs": [],
   "source": [
    "K- Nearest Neighbor\n",
    "\n",
    "https://colab.research.google.com/drive/1_5tGxAoxrWulPmwK2Ht9BHGsS-EpxVo0?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "736ef147bda8415d8c8731db34732728",
      "0fc5e61f821c4be28c616be367ee06e9",
      "c433b2e07f75435c9fad22b9eaa586aa",
      "d4bf3a28a428414f81187b851de2c61f",
      "d4f71da5a2b44d348d742a216d9f2244",
      "61b496e597ab4d3eafa01c8d83d17e52",
      "db0df8d36f9a4bc3b853f44ccd25f810",
      "5165ebe17bd44482a548a6edb6813507"
     ]
    },
    "executionInfo": {
     "elapsed": 16650,
     "status": "ok",
     "timestamp": 1606334820604,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "S-h-9uOw_W1-",
    "outputId": "fcc50d87-3d89-4bbb-86a8-6bdcbb7da0ba"
   },
   "outputs": [],
   "source": [
    "# Загрузка изображений\n",
    "\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "transform = None\n",
    "\n",
    "trainset = datasets.CIFAR10(\"content\", train=True, transform = transform ,  download=True)\n",
    "testset = datasets.CIFAR10(\"content\", train = False, transform = transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 1625,
     "status": "ok",
     "timestamp": 1606335206995,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "MhRzzRB6_8xV",
    "outputId": "58529214-bf92-4d7e-e4af-e46a156981c2"
   },
   "outputs": [],
   "source": [
    "# Выведем несколько картинок вместе с метками\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "# Загрузим названия классов. Исключительно для наглядности, для обучения модели они не нужны.\n",
    "with open(\"content/cifar-10-batches-py/batches.meta\",'rb') as infile:\n",
    "  cifar_meta = pickle.load(infile)\n",
    "labels = cifar_meta['label_names']\n",
    "\n",
    "# В тензоре изображения хранятьтся в формате СxHxW \n",
    "# Что бы вывести их стадтартным способом нужно преобразовать их к HxWxC\n",
    "def to_img(tens):\n",
    "    # И денормализовать если перед этим происходила нормализация\n",
    "    # img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = tens.numpy()\n",
    "    retnp.pose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "  image, class_num = trainset[j]\n",
    "  plt.subplot(1, 10 ,j+1)\n",
    "  plt.imshow(image)\n",
    "  plt.axis('off')  \n",
    "\n",
    "  plt.title(labels[class_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYqGpeY7C4XP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import random \n",
    "\n",
    "\n",
    "class NearestNeighbor:\n",
    "  def __init__(self):\n",
    "    self.train_data = None\n",
    "    self.train_labels = None\n",
    "\n",
    "  def train(self,x,y):\n",
    "    self.train_data = torch.vstack((self.train_data,x)) if self.train_data != None else x\n",
    "    self.train_labels = torch.hstack((self.train_labels,y)) if self.train_labels != None else y\n",
    "   \n",
    "  \n",
    "  def predict(self,x):\n",
    "    # x.shape 3x32x32\n",
    "    diff = self.train_data - x\n",
    "    abs = torch.abs(diff)\n",
    "    distances = torch.sum(abs,dim = (1,2,3)) # Axis 0 it's a row num in image list \n",
    "    return self.train_labels[torch.argmin(distances)]\n",
    "\n",
    "model = NearestNeighbor()\n",
    "\n",
    "\n",
    "trainset.transform = transforms.Compose([ transforms.ToTensor(),  ]) # PIL Image to Pytorch tensor\n",
    "train_dataloder = DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "\n",
    "\n",
    "for img_batch, labels_batch in train_dataloder:\n",
    "  model.train(img_batch, labels_batch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 5967,
     "status": "ok",
     "timestamp": 1606339059422,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "vge98_CHQPTd",
    "outputId": "e51687a3-8145-471d-c8bc-81fc2cb139a7"
   },
   "outputs": [],
   "source": [
    "# Проверим работу модели на нескольких изображениях из тестового набора данных\n",
    "  \n",
    "testset.transform = transforms.Compose([ transforms.ToTensor(),  ])\n",
    "test_dataloder = DataLoader(testset, batch_size=10 ,shuffle=True)\n",
    "img_batch, class_num_batch = next(iter(test_dataloder))\n",
    "#print(test_batch.shape)\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "  label_ind = model.predict(img_batch[j])\n",
    "\n",
    "  img = img_batch[j].permute(1,2,0).numpy()*255  \n",
    "  plt.subplot(1, 10,j+1)\n",
    "  plt.imshow(img.astype(int))\n",
    "  plt.axis('off')\n",
    "\n",
    "  plt.title(labels[int(label_ind)])\n",
    "  #j += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ac_JzpiZRkl3"
   },
   "outputs": [],
   "source": [
    "# Посчтитать Accuracy\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def validate(model,x_test,y_test):\n",
    "  y_predicted = []\n",
    "  for i, sample in enumerate(x_test):\n",
    "    index = model.predict(sample)\n",
    "    y_predicted.append(index) \n",
    "  return accuracy_score(y_test, y_predicted)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testset.transform = transforms.Compose([ transforms.ToTensor(),  ])\n",
    "test_dataloder = DataLoader(testset, batch_size=1024 ,shuffle=True)\n",
    "\n",
    "start = time.perf_counter()\n",
    "for img_batch, class_num_batch in test_dataloder:\n",
    "  accuracy = validate(model,img_batch,class_num_batch)   \n",
    "  tm = time.perf_counter() - start\n",
    "  total = img_batch.shape[0]\n",
    "  print(\"Accuracy {:.2f} Train {:d} /test {:d} in {:.1f} sec. speed {:.2f} samples per second.\".format(accuracy,total,total,tm,total/tm,) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01wgF3h7T9nc"
   },
   "outputs": [],
   "source": [
    "# Implementation of KNN (optionally)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "class KNearestNeighbor(NearestNeighbor):\n",
    "  def __init__(self,k):\n",
    "    self.k = k\n",
    "    pass\n",
    "  \n",
    "  def predict(self,x):\n",
    "    distances = np.sum(np.abs(self.train_data - x),axis = 1)\n",
    "    sorted_distance_indexes = np.argsort(distances)\n",
    "    k_nearest_images = sorted_distance_indexes[:self.k]\n",
    "    most_common = Counter(self.train_labels[k_nearest_images]).most_common()\n",
    "    return most_common[0][0]\n",
    "\n",
    "knn = KNearestNeighbor(7)\n",
    "knn.train( x_train,y_train)\n",
    "validate(knn,x_test,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PCVXf2iUKNp"
   },
   "outputs": [],
   "source": [
    "# Здесь посчитать precision и recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vv9Jyhv6NM1"
   },
   "source": [
    "# Чулан"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12191,
     "status": "ok",
     "timestamp": 1606045672331,
     "user": {
      "displayName": "Антон Ганичев",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBGUeRQ7Tx1PE7ge5LPPM4do9SVS7xoYoHEjDg=s64",
      "userId": "03960392406657956647"
     },
     "user_tz": -180
    },
    "id": "ixgpb2CXxBdH",
    "outputId": "56ab75da-becf-41ac-cf68-ec89147dcf62"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/brinkar/real-world-machine-learning.git\n",
    "\n",
    "\n",
    "#Примеры из кники Х. Бринк \"Real world machine learning\"\n",
    "https://github.com/brinkar/real-world-machine-learning/blob/master/Chapter%203%20-%20Modeling%20and%20prediction.ipynb\n",
    "\n",
    "# Либо на toy-датасетах из scikit-learn что более легко воспроизводимо \n",
    "https://scikit-learn.org/stable/datasets/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k21OAuXuOSS4"
   },
   "outputs": [],
   "source": [
    "! pip install torchtext spacy\n",
    "!python -m spacy download en\n",
    "!python -m spacy download de\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEnxK3LQKbu-"
   },
   "outputs": [],
   "source": [
    "# Пример загрузки текста \n",
    "\n",
    "# https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n",
    "# https://pytorch.org/text/stable/datasets.html#multi30k\n",
    "# Документация с пояснениями\n",
    "# https://dzlab.github.io/dltips/en/pytorch/basic-nlp-pytorch-text/\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "#multi30k = torchtext.datasets.Multi30k(\"sample_data\", exts, fields, **kwargs)\n",
    "\n",
    "SRC = Field(tokenize = \"spacy\", tokenizer_language=\"de\", init_token = '<sos>', eos_token = '<eos>', lower = True)\n",
    "\n",
    "TRG = Field(tokenize = \"spacy\",\n",
    "            tokenizer_language=\"en\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),fields = (SRC, TRG))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDyTq7Pl9eP2RasDVaUj7Y",
   "name": "1.Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fc5e61f821c4be28c616be367ee06e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5165ebe17bd44482a548a6edb6813507": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61b496e597ab4d3eafa01c8d83d17e52": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "736ef147bda8415d8c8731db34732728": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c433b2e07f75435c9fad22b9eaa586aa",
       "IPY_MODEL_d4bf3a28a428414f81187b851de2c61f"
      ],
      "layout": "IPY_MODEL_0fc5e61f821c4be28c616be367ee06e9"
     }
    },
    "c433b2e07f75435c9fad22b9eaa586aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61b496e597ab4d3eafa01c8d83d17e52",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4f71da5a2b44d348d742a216d9f2244",
      "value": 1
     }
    },
    "d4bf3a28a428414f81187b851de2c61f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5165ebe17bd44482a548a6edb6813507",
      "placeholder": "​",
      "style": "IPY_MODEL_db0df8d36f9a4bc3b853f44ccd25f810",
      "value": " 170500096/? [00:30&lt;00:00, 17499045.46it/s]"
     }
    },
    "d4f71da5a2b44d348d742a216d9f2244": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "db0df8d36f9a4bc3b853f44ccd25f810": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
